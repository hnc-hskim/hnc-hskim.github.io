[
{
	"uri": "https://hnc-hskim.github.io/workshop/msa/definition/",
	"title": "Definition",
	"tags": [],
	"description": "",
	"content": "출처 : 위키디피아\n정의 마이크로서비스(microservice)는 애플리케이션을 느슨하게 결합된 서비스의 모임으로 구조화하는 서비스 지향 아키텍처(SOA) 스타일의 일종인 소프트웨어 개발 기법이다. 마이크로서비스 아키텍처에서 서비스들은 섬세(fine-grained)하고 프로토콜은 가벼운 편이다. 애플리케이션을 더 조그마한 여러 서비스로 분해할 때의 장점은 모듈성을 개선하고 애플리케이션의 이해, 개발, 테스트를 더 쉽게 해주고 애플리케이션 침식에 더 탄력적으로 만들어 준다. 규모가 작은 자율적인 팀들이 팀별 서비스를 독립적으로 개발, 전개, 규모 확장을 할 수 있게 함으로써 병렬로 개발할 수 있게 한다. 또, 지속적인 리팩터링을 통해 개개의 서비스 아키텍처가 하나로 병합될 수 있게 허용한다. 마이크로서비스 기반 아키텍처는 지속적 배포를 가능케 한다.\n개요 마이크로서비스의 속성과 관련하여 아직 산업적인 합의는 없으며 공식적인 정의도 없다.\n\r특징들 가운데 일부는 다음을 포함한다:\n 마이크로서비스 아키텍처(microservice architecture, MSA)의 서비스들은 HTTP와 같은 기술 불가지론적인 프로토콜을 사용하여 목표를 달성하기 위해 네트워크를 통해 통신하는 프로세스들인 경우도 있다. 그러나, 서비스들은 공유 메모리와 같은 다른 종류의 프로세스 간 통신 메커니즘을 사용할 수도 있다. 서비스들은 이를테면 OSGI 번들에서처럼 동일한 프로세스 내에서 실행할 수 있다. 마이크로서비스 아키텍처의 서비스들은 독립적인 전개(deploy)가 가능하다. 서비스의 교체가 쉽다. 서비스는 기능별로 분류된다. (예: 사용자 인터페이스 프론트엔드, 추천, 로지스틱스, 청구서 발부 등) 서비스는 최적의 조건에 부합하는 바에 따라 각기 다른 프로그래밍 언어, 데이터베이스, 하드웨어, 소프트웨어 환경을 사용하여 구현할 수 있다. 서비스들은 규모가 작고, 메시지 전달이 가능하며 컨텍스트별로 묶이며 자율적으로 개발되며 독립적으로 전개할 수 있으며 분산적이며 빌드가 되며 자동화된 프로세스들로 출시된다.  마이크로서비스 기반 아키텍처는:\n 모듈성이 있는 구조를 자연스럽게 강제한다. 자기 자신을 지속적 배포 소프트웨어 개발 프로세스에 위치시킨다. 애플리케이션의 사소한 부분의 변경은 하나 이상의 적은 수의 서비스의 다시 빌드, 재전개만을 필요로 한다. 섬세(fine-grained)한 인터페이스(독립적으로 서비스를 전개할 수 있음), 비즈니스 주도의 개발(예: 도메인 드리븐 디자인), 클라우드 애플리케이션 아키텍처, 폴리곳 프로그래밍, 퍼시스턴스, 가벼운 컨테이너 전개, 탈중심화된 지속적 배포, 전체론적인 서비스 모니터링을 갖춘 데브옵스와 같은 원칙들을 고수한다. 확장성에 이득이 되는 특징들을 제공한다.  "
},
{
	"uri": "https://hnc-hskim.github.io/workshop/spring/springboot/",
	"title": "Springboot",
	"tags": [],
	"description": "",
	"content": "\r오픈 소스 마이크로 프레임워크입니다. 따라서 마이크로 서비스 기반 Spring 애플리케이션을 만드는 데 도움이 됩니다. Pivotal Software, Inc.에서 개발합니다.\n\r참고\nVS code에 스프링부트 설치하기 1. 사전 준비  Java Development Kit(JDK): 8 이상(11이상 권장) VSCode Java Extension Pack: https://marketplace.visualstudio.com/items?itemName=vscjava.vscode-java-pack VSCode : https://code.visualstudio.com/download  jdk 환경변수 설정(Window) # 커맨드에서 아래명령을 입력했을때 버전이 표시되지 않으면 환경 변수 설정을 해준다. $ javac -version javac 18.0.2\r# window key + R을 누른뒤, sysdm.cpl을 입력한다.(시작 버튼을 누른뒤 검색에서 고급 시스템 설정을 검색해도 됨)\r# 고급탭에 환경변수를 누른다. # 시스템 변수에 새로 만들기를 선택한다. 변수 이름(N) : JAVA_HOME\r변수 값(V) : C:\\Program Files\\Java\\jdk1.8.0_281 (JDK가 설치된 경로)\r# 시스템 변수의 Path를 눌러 편집을 클릭한다. # 새로 만들기를 클릭한후 다음을 입력한다. %JAVA_HOME%bin 2. Extension pack 설치  Java Extension Pack - Microsoft: https://marketplace.visualstudio.com/items?itemName=vscjava.vscode-java-pack Spring Boot Extension Pack - Pivotal: https://marketplace.visualstudio.com/items?itemName=Pivotal.vscode-boot-dev-pack  Spring Boot Tools - Pivotal: https://marketplace.visualstudio.com/items?itemName=Pivotal.vscode-spring-boot ‘Spring Boot Tools’ 확장팩은 다음 파일 패턴을 가지는 파일에 대해서 파일수정할 때 활성화된다.\n.java: 스프링 부트 사양을 따르는 경우(@SpringBoot 애너테이션과 main() 메서드가 함께있음) 활성화\napplication*.properties\napplication*.yml\n\r Spring Initializr Java Support - Microsoft : https://marketplace.visualstudio.com/items?itemName=vscjava.vscode-spring-initializr ‘Spring Initializr Java Support’ 확장팩은 VSCode 내에서 Spring Initialzr(https://start.spring.io/) API를 이용하여 스프링 부트 프로젝트를 구성할 수 있다.\n\r Spring Boot Dashboard - Microsoft: https://marketplace.visualstudio.com/items?itemName=Pivotal.vscode-boot-dev-pack ‘Spring Initializr Java Support’ 확장팩은 VSCode 내에서 Spring Initialzr(https://start.spring.io/) API를 이용하여 스프링 부트 프로젝트를 구성할 수 있다.\n\r   Lombok Annotations Support for VS Code : https://marketplace.visualstudio.com/items?itemName=GabrielBB.vscode-lombok  3. 프로젝트 생성 및 실행  Ctrl + Shift + P를 눌러 Command palette 열기   Spring Boot version 선택: 2.7.2 Project language 선택: Java Group Id 등록: ex) test.springboot.vscode Artifact Id 등록: test-vs-code Packaging type 선택: JAR Java Version 선택: 18 Dependnecies 선택  Spring Boot DevTools Lombok Spring Configuration Processor Spring Web Spring Data JPA H2 Database Flyway Migration MariaDB Driver   저장 위치 선택   4. 완료 화면 5. application.properties 파일 확장자 application.yml로 변경  yaml 파일 형식이 가독성이 좋고 작성이 쉽기 때문에 변경한다. 파일 위치 : src/main/resources/application.yml  logging:\rlevel:\r\u0026#39;[org.springframework.web]\u0026#39;: debug 6. HelloWorldController.java 추가 package test.springboot.vscode.testvscode.web;\rimport org.springframework.web.bind.annotation.GetMapping;\rimport org.springframework.web.bind.annotation.RestController;\rimport lombok.RequiredArgsConstructor;\rimport test.springboot.vscode.testvscode.service.HelloWorldService;\r@RestController\r@RequiredArgsConstructor\rpublic class HelloWorldController {\rprivate final HelloWorldService helloService;\r@GetMapping(\u0026#34;/hello\u0026#34;)\rpublic String hello() {\rreturn helloService.hello();\r}\r} 7. HelloWorldService.java 추가 package test.springboot.vscode.testvscode.service;\rimport org.springframework.stereotype.Service;\r@Service\rpublic class HelloWorldService {\rpublic String hello() {\rreturn \u0026#34;Hello, World!!!\u0026#34;;\r}\r} 8. 실행  Spring Boot Dashboard 선택후 Run 아이콘 클릭   9. 완료 화면 "
},
{
	"uri": "https://hnc-hskim.github.io/workshop/msa/concept/",
	"title": "Concept",
	"tags": [],
	"description": "",
	"content": "\r아래에 사용된 예제는 NodeJS, ExpressJS, MongoDB를 이용하여 구성되었습니다.\n\rReferences  https://dev.to/zachgoll/introduction-to-software-architecture-monolithic-vs-layered-vs-microservices-452 https://www.atlassian.com/ko/microservices/microservices-architecture/microservices-vs-monolith https://github.com/zachgoll/layered-architecture-example-app    Diagram Editor mermaid flowchart syntax  모놀리식 아키텍처는 소프트웨어 프로그램의 전통적인 모델로, 자체 포함 방식이며 다른 애플리케이션과 독립적인 통합된 유닛으로 만들어집니다. “모놀리스\u0026quot;라는 단어는 거대하고 빙하 같은 것을 의미하는 경우가 많은데, 소프트웨어 설계의 모놀리식 아키텍처도 크게 다르지 않습니다. 모놀리식 아키텍처는 모든 비즈니스 관련 사항을 함께 결합하는 하나의 코드 베이스를 갖춘 대규모의 단일 컴퓨팅 네트워크입니다.\n\r1. 모놀리식 아키텍처 VS 마이크로서비스 아키텍처 Monolithic Architecture 전통적인 모놀로식 아키텍처가 비효율적으로 보일 수 있지만 간단한 아키텍처의 경우 모놀리식 아키텍처도 충분히 활용 가능한 솔루션이라고 할 수 있습니다. 시작부터 마이크로 서비스를 고려하는것이 나쁜것은 아니지만 개발중인 애플리케이션이 충분히 복잡하지 않다면 마이크로서비스 아키텍처의 이점을 확인하기는 쉽지 않습니다. 모놀로딕 아키텍처로 시작하여 서비스 확장에 따라 마이크로 서비스 아키텍처로 리팩토링하는것이 효율적인 개발 방법일수도 있습니다.\n장점    장점 설명     손쉬운 배포 실행 파일 또는 디렉토리가 하나여서 배포가 더 쉽습니다.   개발 하나의 코드 베이스로 애플리케이션을 구축하여 개발이 더 쉽습니다.   성능 중앙 집중식 코드 베이스 및 리포지토리에서는 대부분 하나의 API만으로 마이크로서비스에서 여러 API가 수행하는 것과 동일한 기능을 수행할 수 있습니다.   테스트 간소화 모놀리식 애플리케이션은 하나의 중앙 집중식 장치이므로 분산된 애플리케이션보다 엔드투엔드 테스트를 더 빠르게 수행할 수 있습니다.   간편한 디버깅 모든 코드가 한 곳에 있으므로 요청을 따라가서 문제를 찾기가 더 쉽습니다.    단점    단점 설명     느린 개발 속도 대규모 모놀리식 애플리케이션에서는 개발이 더욱 복잡해지고 속도가 느려집니다.   확장성 개별 컴포넌트를 확장할 수 없습니다.   안정성 모듈에 오류가 있으면 애플리케이션 전체의 가용성에 영향을 줄 수 있습니다.   기술 채택의 장벽 프레임워크 또는 언어를 변경하면 애플리케이션 전체에 영향을 미치므로 변경 시 비용과 시간이 많이 소요되는 경우가 많습니다.   유연성 부족 모놀리스의 경우 모놀리스에서 이미 사용한 기술로 제한됩니다.   배포 모놀리식 애플리케이션을 약간만 변경하는 경우에도 전체 모놀리스를 다시 배포해야 합니다.    애플리케이션 구조 아래의 코드를 통해 monolithic 구조를 살펴보자. (이 예는 Monolithic 아키텍처를 설명하기 위한것으로 구조화되지 않은것이 Monolithic 아키텍처의 특징으로 오해하면 안된다. )\n[monolithic architecture example github] https://github.com/zachgoll/monolithic-architecture-example-app\n이 코드에서 확인 가능한것은 애플리케이션간의 구분이 없다는것이다. app.js에서 데이터베이스, 서버 및 API 엔드포인트에 대한 연결을 확인할 수 있다.\nconst express = require(\u0026#34;express\u0026#34;); const app = express(); const mongoose = require(\u0026#34;mongoose\u0026#34;); const cors = require(\u0026#34;cors\u0026#34;); const bodyParser = require(\u0026#34;body-parser\u0026#34;);  // This will allow our presentation layer to retrieve data from this API without // running into cross-origin issues (CORS) app.use(cors()); app.use(bodyParser.json());  // ============================================ // ========== DATABASE CONNECTION =========== // ============================================ // Connect to running database mongoose.connect(  `mongodb://${process.env.DB_USER}:${process.env.DB_PW}@127.0.0.1:27017/monolithic_app_db`,  { useNewUrlParser: true } );  // User schema for mongodb const UserSchema = mongoose.Schema(  {  name: { type: String },  email: { type: String },  },  { collection: \u0026#34;users\u0026#34; } );  // Define the mongoose model for use below in method const User = mongoose.model(\u0026#34;User\u0026#34;, UserSchema);  function getUserByEmail(email, callback) {  try {  User.findOne({ email: email }, callback);  } catch (err) {  callback(err);  } }  // set the view engine to ejs app.set(\u0026#34;view engine\u0026#34;, \u0026#34;ejs\u0026#34;);  // index page app.get(\u0026#34;/\u0026#34;, function (req, res) {  res.render(\u0026#34;home\u0026#34;); });  // ============================================ // ============ API ENDPOINT ================ // ============================================ app.post(\u0026#34;/register\u0026#34;, function (req, res) {  const newUser = new User({  name: req.body.name,  email: req.body.email,  });   newUser.save((err, user) =\u0026gt; {  res.status(200).json(user);  }); });  // ============================================ // ============== SERVER ===================== // ============================================ app.listen(8080); console.log(\u0026#34;Visit app at http://localhost:8080\u0026#34;); 이 모놀리딕 애플리케이션이 확장하기 시작할 경우 빠르게 코드는 엉망이 될 것이다. 이 단계에서 대부분 마이크로서비스 아키텍처로의 전환을 선택하지만, 리팩토링을 통하여 계층화된 아키텍처로 바꾸는것을 다른 하나의 옵션으로 고민해 볼 수 있다.\nMonolithic Architecture (with better \u0026ldquo;layered\u0026rdquo; or \u0026ldquo;n-tier\u0026rdquo; design) 계층화된 아키텍처는 애플리케이션을 일반적으로 다음과 같은 레이어들로 분할할 수 있다.\n 프리젠테이션 계층(Presentation Layer) 비지니스 계층(Business Layer) 데이터 액세스 계층(Data Access Layer)  다른 형태로 다음과 같은 레이어로 분류할 수도 있다.\n Presentation Layer Application Layer Domain Layer Persistence Layer  Layered Architecture Diagram flowchart TD subgraph Presentation-Layer\rdirection LR\rAngular --- A{{Closed}}\rend\rsubgraph Business-Layer\rdirection LR\rExpress --- B{{Closed}}\rend\rsubgraph Shared-Utilities-Layer\rdirection LR\rString-Utilities --- Object-Transformation-Utilities --- C{{Open}}\rend\rsubgraph Data-Layer\rdirection LR\rMongo --- D{{Closed}}\rend Presentation-Layer -- Business-Layer\rBusiness-Layer -- Shared-Utilities-Layer\rShared-Utilities-Layer -- Data-Layer click Angular \"https://www.github.com\" _blank\r\r중요한 점은 각 레이어 구조에서 바로 아래 레이어만 사용할 수 있게 하도록 구조를 분리하는것입니다. 하지만 Utility 레이어의 경우처럼 때로는 공유하여 쓸수 있는 레이어가 필요할 수도 있습니다. 다이어그램에서 모든 레이어에서 사용할 수 있도록 열린 레이어로 생성한것을 확인할 수 있습니다.\nApplication Structure 위에서 언급한대로 계층화된 아키텍처에서는 각 계층이 바로 아래 계층만 사용할수 있다는 규칙이 있습니다. 그럼 이 중요한 규칙을 기반으로 monolothic archicture를 변경해 보겠습니다.\n 프레젠테이션 계층은 HTML 사용자 양식에서 호출합니다. 프레젠테이션 계층 자바스크립트는 양식을 처리하고 비즈니스 계층에 대한 호출을 실행합니다. 비즈니스 계층은 양식 정보를 처리하고 데이터 액세스 계층을 호출합니다. 데이터 액세스 계층은 정보를 처리하고 사용자를 위해 데이터베이스에 쿼리합니다. 데이터 액세스 계층은 비즈니스 계층에 정보를 반환합니다. 비즈니스 계층은 HTTP를 통해 프레젠테이션 계층에 정보를 반환합니다. 프레젠테이션 레이어는 새로운 정보로 뷰를 렌더링합니다.  1. 프레젠테이션 계층은 HTML 사용자 양식에서 호출합니다. \u0026lt;!-- File: home.ejs --\u0026gt;  \u0026lt;!-- On form submit, home.ejs executes the getDataFromBusinessLayer() function --\u0026gt;  \u0026lt;form id=\u0026#34;emailform\u0026#34; onsubmit=\u0026#34;getDataFromBusinessLayer()\u0026#34;\u0026gt;  \u0026lt;input name=\u0026#34;email\u0026#34; id=\u0026#34;email\u0026#34; placeholder=\u0026#34;Enter email...\u0026#34; /\u0026gt;  \u0026lt;button type=\u0026#34;submit\u0026#34;\u0026gt;Load Profile\u0026lt;/button\u0026gt; \u0026lt;/form\u0026gt; 2. 프리젠테이션 계층 자바스크립트는 양식을 처리하고 비즈니스 계층에 대한 호출을 실행합니다. // File: presentation-layer-user.js  function getDataFromBusinessLayer() {  event.preventDefault();  const email = $(\u0026#34;#email\u0026#34;).val();   // Perform the GET request to the business layer  // ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^  $.ajax({  url: `http://localhost:8081/get-user/${email}`,  type: \u0026#34;GET\u0026#34;,  success: function (user) {  // Render the user object on the page  // Ommitted for brevity  },  error: function (jqXHR, textStatus, ex) {  console.log(textStatus + \u0026#34;,\u0026#34; + ex + \u0026#34;,\u0026#34; + jqXHR.responseText);  },  }); } 비즈니스 계층은 양식 정보를 처리하고 데이터 액세스 계층을 호출합니다.  // File: business-layer-user.js  app.get(\u0026#34;/get-user/:useremail\u0026#34;, function (req, res) {  // Makes a call to the data access layer  // ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^  const user = User.getUserByEmail(req.params.useremail, (error, user) =\u0026gt; {  res.status(200).json({  name: user.name,  email: user.email,  profileUrl: user.profileUrl,  });  }); }); 데이터 접근 계층은 정보를 처리하고 사용자를 위해 데이터베이스에 쿼리합니다.  // File: data-layer-user.js  module.exports.getUserByEmail = (email, callback) =\u0026gt; {  try {  // Makes a call to the database  // ^^^^^^^^^^^^^^^^^^^^^^^^^^^^  User.findOne({ email: email }, callback);  } catch (err) {  callback(err);  } };  데이터 액세스 계층은 비즈니스 계층에 정보를 반환합니다.\n  비즈니스 계층은 HTTP를 통해 프레젠테이션 계층에 정보를 반환합니다.\n  프레젠테이션 레이어는 새로운 정보로 뷰를 렌더링합니다.\n  각 단계를 통해 계층이 담당하는 구체적인 의무를\n"
},
{
	"uri": "https://hnc-hskim.github.io/workshop/spring/springboot-gradle/",
	"title": "Springboot Gradle",
	"tags": [],
	"description": "",
	"content": "References  https://inma.tistory.com/148  $ java -version\njava version \u0026ldquo;18.0.2\u0026rdquo; 2022-07-19\nJava(TM) SE Runtime Environment (build 18.0.2+9-61)\nJava HotSpot(TM) 64-Bit Server VM (build 18.0.2+9-61, mixed mode, sharing)\n\rgradle 빌드 방법  프로젝트 루트로 이동후 gradlew jar 명령어 입력  $ ./gradlew jar\rStarting a Gradle Daemon, 2 incompatible and 2 stopped Daemons could not be reused, use --status for details\rBUILD SUCCESSFUL in 19s\r3 actionable tasks: 3 executed  실행 가능한 jar 파일 만들기  $ ./gradlew bootJar\rBUILD SUCCESSFUL in 4s\r4 actionable tasks: 4 up-to-date jar 파일 위치 build/libs/*.jar \rJAR(Java Archive, 자바 아카이브)는 여러개의 자바 클래스 파일과, 클래스들이 이용하는 관련 리소스(텍스트, 그림 등) 및 메타데이터를 하나의 파일로 모아서 자바 플랫폼에 응용 소프트웨어나 라이브러리를 배포하기 위한 소프트웨어 패키지 파일 포맷이다. JAR 파일은 실제로 ZIP 파일 포맷으로 이루어진 압축 파일로서, 파일 확장자는 .jar이다.\n컴퓨터 사용자들은 JDK에 포함된 jar 명령어를 이용하여 JAR 파일을 만들거나 압축을 풀 수 있다.\n또, zip 도구를 사용할 수도 있으나 압축 시에는 매니페스트 파일이 처음이어야 하는 경우가 있어서 zip 파일 헤더의 엔트리 순서가 중요하다.\nJAR 안에서 파일 이름들은 유니코드 텍스트로 되어 있다.\n\rjar 파일 실행 $ java -jar .\\test-vs-code-0.0.1-SNAPSHOT.jar\r. ____ _ __ _ _\r/\\\\ / ___\u0026#39;_ __ _ _(_)_ __ __ _ \\ \\ \\ \\\r( ( )\\___ | \u0026#39;_ | \u0026#39;_| | \u0026#39;_ \\/ _` | \\ \\ \\ \\\r\\\\/ ___)| |_)| | | | | || (_| | ) ) ) )\r\u0026#39; |____| .__|_| |_|_| |_\\__, | / / / /\r=========|_|==============|___/=/_/_/_/\r:: Spring Boot :: (v2.7.2)\r2022-08-05 17:25:32.578 INFO 11512 --- [ main] t.s.v.testvscode.TestVsCodeApplication : Starting TestVsCodeApplication using Java 18.0.2 on DESKTOP-SC8B9ID with PID 11512 (C:\\work2022\\git\\hnc-hskim\\samples\\springboot\\test-vs-code\\build\\libs\\test-vs-code-0.0.1-SNAPSHOT.jar started by hskim in C:\\work2022\\git\\hnc-hskim\\samples\\springboot\\test-vs-code\\build\\libs)\r2022-08-05 17:25:32.585 INFO 11512 --- [ main] t.s.v.testvscode.TestVsCodeApplication : No active profile set, falling back to 1 default profile: \u0026#34;default\u0026#34;\r2022-08-05 17:25:33.647 INFO 11512 --- [ main] .s.d.r.c.RepositoryConfigurationDelegate : Bootstrapping Spring Data JPA repositories in DEFAULT mode.\r2022-08-05 17:25:33.674 INFO 11512 --- [ main] .s.d.r.c.RepositoryConfigurationDelegate : Finished Spring Data repository scanning in 11 ms. Found 0 JPA repository interfaces.\r2022-08-05 17:25:34.711 INFO 11512 --- [ main] o.s.b.w.embedded.tomcat.TomcatWebServer : Tomcat initialized with port(s): 8080 (http)\r2022-08-05 17:25:34.733 INFO 11512 --- [ main] o.apache.catalina.core.StandardService : Starting service [Tomcat]\r2022-08-05 17:25:34.734 INFO 11512 --- [ main] org.apache.catalina.core.StandardEngine : Starting Servlet engine: [Apache Tomcat/9.0.65]\r2022-08-05 17:25:34.874 INFO 11512 --- [ main] o.a.c.c.C.[Tomcat].[localhost].[/] : Initializing Spring embedded WebApplicationContext\r2022-08-05 17:25:34.875 INFO 11512 --- [ main] w.s.c.ServletWebServerApplicationContext : Root WebApplicationContext: initialization completed in 2140 ms\r2022-08-05 17:25:35.172 INFO 11512 --- [ main] o.f.c.internal.license.VersionPrinter : Flyway Community Edition 8.5.13 by Redgate\r2022-08-05 17:25:35.173 INFO 11512 --- [ main] o.f.c.internal.license.VersionPrinter : See what\u0026#39;s new here: https://flywaydb.org/documentation/learnmore/releaseNotes#8.5.13\r2022-08-05 17:25:35.173 INFO 11512 --- [ main] o.f.c.internal.license.VersionPrinter :\r2022-08-05 17:25:35.188 INFO 11512 --- [ main] com.zaxxer.hikari.HikariDataSource : HikariPool-1 - Starting...\r2022-08-05 17:25:35.514 INFO 11512 --- [ main] com.zaxxer.hikari.HikariDataSource : HikariPool-1 - Start completed.\r2022-08-05 17:25:35.531 INFO 11512 --- [ main] o.f.c.i.database.base.BaseDatabaseType : Database: jdbc:h2:mem:6c0933b2-c77b-474d-9973-17e89d02a625 (H2 2.1)\r2022-08-05 17:25:35.587 WARN 11512 --- [ main] o.f.c.internal.database.base.Database : Flyway upgrade recommended: H2 2.1.214 is newer than this version of Flyway and support has not been tested. The latest supported version of H2 is 2.1.210.\r2022-08-05 17:25:35.615 INFO 11512 --- [ main] o.f.core.internal.command.DbValidate : Successfully validated 0 migrations (execution time 00:00.007s)\r2022-08-05 17:25:35.615 WARN 11512 --- [ main] o.f.core.internal.command.DbValidate : No migrations found. Are your locations set up correctly?\r2022-08-05 17:25:35.627 INFO 11512 --- [ main] o.f.c.i.s.JdbcTableSchemaHistory : Creating Schema History table \u0026#34;PUBLIC\u0026#34;.\u0026#34;flyway_schema_history\u0026#34; ...\r2022-08-05 17:25:35.664 INFO 11512 --- [ main] o.f.core.internal.command.DbMigrate : Current version of schema \u0026#34;PUBLIC\u0026#34;: \u0026lt;\u0026lt; Empty Schema \u0026gt;\u0026gt;\r2022-08-05 17:25:35.667 INFO 11512 --- [ main] o.f.core.internal.command.DbMigrate : Schema \u0026#34;PUBLIC\u0026#34; is up to date. No migration necessary.\r2022-08-05 17:25:35.946 INFO 11512 --- [ main] o.hibernate.jpa.internal.util.LogHelper : HHH000204: Processing PersistenceUnitInfo [name: default]\r2022-08-05 17:25:36.075 INFO 11512 --- [ main] org.hibernate.Version : HHH000412: Hibernate ORM core version 5.6.10.Final\r2022-08-05 17:25:36.367 INFO 11512 --- [ main] o.hibernate.annotations.common.Version : HCANN000001: Hibernate Commons Annotations {5.1.2.Final}\r2022-08-05 17:25:36.649 INFO 11512 --- [ main] org.hibernate.dialect.Dialect : HHH000400: Using dialect: org.hibernate.dialect.H2Dialect\r2022-08-05 17:25:37.074 INFO 11512 --- [ main] o.h.e.t.j.p.i.JtaPlatformInitiator : HHH000490: Using JtaPlatform implementation: [org.hibernate.engine.transaction.jta.platform.internal.NoJtaPlatform]\r2022-08-05 17:25:37.092 INFO 11512 --- [ main] j.LocalContainerEntityManagerFactoryBean : Initialized JPA EntityManagerFactory for persistence unit \u0026#39;default\u0026#39;\r2022-08-05 17:25:37.205 WARN 11512 --- [ main] JpaBaseConfiguration$JpaWebConfiguration : spring.jpa.open-in-view is enabled by default. Therefore, database queries may be performed during view rendering. Explicitly configure spring.jpa.open-in-view to disable this warning\r2022-08-05 17:25:37.486 DEBUG 11512 --- [ main] s.w.s.m.m.a.RequestMappingHandlerAdapter : ControllerAdvice beans: 0 @ModelAttribute, 0 @InitBinder, 1 RequestBodyAdvice, 1 ResponseBodyAdvice\r2022-08-05 17:25:37.721 DEBUG 11512 --- [ main] s.w.s.m.m.a.RequestMappingHandlerMapping : 3 mappings in \u0026#39;requestMappingHandlerMapping\u0026#39;\r2022-08-05 17:25:37.775 DEBUG 11512 --- [ main] o.s.w.s.handler.SimpleUrlHandlerMapping : Patterns [/webjars/**, /**] in \u0026#39;resourceHandlerMapping\u0026#39;\r2022-08-05 17:25:37.809 DEBUG 11512 --- [ main] .m.m.a.ExceptionHandlerExceptionResolver : ControllerAdvice beans: 0 @ExceptionHandler, 1 ResponseBodyAdvice\r2022-08-05 17:25:38.042 INFO 11512 --- [ main] o.s.b.w.embedded.tomcat.TomcatWebServer : Tomcat started on port(s): 8080 (http) with context path \u0026#39;\u0026#39;\r2022-08-05 17:25:38.066 INFO 11512 --- [ main] t.s.v.testvscode.TestVsCodeApplication : Started TestVsCodeApplication in 6.269 seconds (JVM running for 7.013) Gradle Extension 설치  https://marketplace.visualstudio.com/items?itemName=vscjava.vscode-gradle  # 중첩 Gradle 프로젝트 검색은 기본적으로 활성화되어 있지 않으며 활성화하도록 설정하려면 다음을 셋티한다. # .vscode의 settings.json파일에 환경변수를 등록한다. {\r\u0026#34;java.configuration.updateBuildConfiguration\u0026#34;: \u0026#34;interactive\u0026#34;,\r\u0026#34;gradle.nestedProjects\u0026#34;: true\r}\rjdk설치후 시스템 재시작을 해야 vscode에서 환경변수가 제대로 반영된다. # JAVA_HOME 환경변수 패스확인\rPS\u0026gt; $Env:JAVA_HOME\rC:\\Program Files\\Android\\Jdk\\microsoft_dist_openjdk_1.8.0.25\r# 변경\rPS\u0026gt; $Env:JAVA_HOME = \u0026#34;C:\\Program Files\\Java\\jdk-18.0.2\u0026#34; Gradle 서버 실행 ./gradlew bootRun\r\u0026gt; Task :bootRun\r16:07:25.068 [Thread-0] DEBUG org.springframework.boot.devtools.restart.classloader.RestartClassLoader - Created RestartClassLoader org.springframework.boot.devtools.restart.classloader.RestartClassLoader@24829070\r. ____ _ __ _ _\r/\\\\ / ___\u0026#39;_ __ _ _(_)_ __ __ _ \\ \\ \\ \\\r( ( )\\___ | \u0026#39;_ | \u0026#39;_| | \u0026#39;_ \\/ _` | \\ \\ \\ \\\r\\\\/ ___)| |_)| | | | | || (_| | ) ) ) )\r\u0026#39; |____| .__|_| |_|_| |_\\__, | / / / /\r=========|_|==============|___/=/_/_/_/\r:: Spring Boot :: (v2.7.2) Docker Image 만들기  Dockerfile  # jdk 18 alpine 버전 사용\rFROM openjdk:18-alpine AS builder # gradlew 복사\rCOPY gradlew . # gradle 복사\rCOPY gradle gradle # build.gradle 복사\rCOPY build.gradle . # settings.gradle 복사\rCOPY settings.gradle . # 웹 어플리케이션 소스 복사\rCOPY src src # gradlew 실행권한 부여\rRUN chmod +x ./gradlew # gradlew를 사용하여 실행 가능한 jar 파일 생성\rRUN ./gradlew bootJar # 베이스 이미지\rFROM openjdk:18-alpine\r# builder 이미지에서 build/libs/*.jar 파일을 app.jar로 복사\rCOPY --from=builder build/libs/*.jar app.jar # 컨테이너 Port 노출\rEXPOSE 8080 # jar 파일 실행\rENTRYPOINT [\u0026#34;java\u0026#34;,\u0026#34;-jar\u0026#34;,\u0026#34;/app.jar\u0026#34;] "
},
{
	"uri": "https://hnc-hskim.github.io/workshop/msa/software-architecture-pattern/",
	"title": "Software Architecture Pattern",
	"tags": [],
	"description": "",
	"content": "References  10 Common Software Architectural Patterns in a nutshell Architectural patterns  소프트웨어 아키텍처가 프로젝트의 성공에 중요한 13가지 이유  아키텍처는 시스템의 구동 품질 속성을 억제하거나 활성화합니다. 아키텍처에서 내린 결정을 통해 시스템이 발전함에 따라 변경 사항을 추론하고 관리할 수 있습니다. 아키텍처 분석을 통해 시스템 품질을 조기에 예측할 수 있습니다. 문서화된 아키텍처는 이해 관계자 간의 의사 소통을 향상시킵니다. 아키텍처는 가장 초기에 가장 기본적이고 가장 변경하기 어려운 설계 결정의 전달자입니다. 아키텍처는 후속 구현에 대한 일련의 제약 조건을 정의합니다. 아키텍처는 조직의 구조를 결정하거나 그 반대의 경우도 마찬가지입니다. 아키텍처는 진화적 프로토타이핑의 기초를 제공할 수 있습니다. 아키텍처는 건축가와 프로젝트 관리자가 비용과 일정에 대해 추론할 수 있도록 하는 핵심 아티팩트입니다. 아키텍처는 제품 라인의 핵심을 형성하는 양도 가능하고 재사용 가능한 모델로 생성될 수 있습니다. 아키텍처 기반 개발은 단순히 구성 요소를 만드는 것보다 구성 요소의 조립에 주의를 집중합니다. 설계 대안을 제한함으로써 아키텍처는 개발자의 창의성을 전달하여 설계 및 시스템 복잡성을 줄입니다. 아키텍처는 새로운 팀원을 교육하기 위한 기반이 될 수 있습니다.  10가지 소프트웨어 아키텍처 패턴  계층화 패턴 (Layered pattern) 클라이언트-서버 패턴 (Client-server pattern) 마스터-슬레이브 패턴 (Master-slave pattern) 파이프-필터 패턴 (Pipe-filter pattern) 브로커 패턴 (Broker pattern) 피어 투 피어 패턴 (Peer-to-peer pattern) 이벤트-버스 패턴 (Event-bus pattern) 모델-뷰-컨트롤러 패턴 (Model-view-controller pattern) 블랙보드 패턴 (Blackboard pattern) 인터프리터 패턴 (Interpreter pattern)  1. 계층화 패턴 (Layered pattern) 계층화 패턴에서 흔히 볼 수 있는 4개의 계층은 다음과 같다.\n 프레젠테이션 계층 ( UI 계층 이라고도 함 ) 애플리케이션 계층 ( 서비스 계층 이라고도 함 ) 비즈니스 논리 계층 ( 도메인 계층 이라고도 함 ) 데이터 액세스 계층 ( 지속성 계층 이라고도 함 )  (1) 일반 데스크탑 애플리케이션\n(2) 전자 상거래 웹 애플리케이션\n\r2. 클라이언트-서버 패턴 (Client-server pattern) 흔히 사용되는 패턴입니다. 서버와 여러 클라이언트가 존재할 수 있습니다. 서버는 여러 클라이언트에 서비스를 제공합니다.\n 클라이언트는 서버에 서비스 요청 서버는 클라이언트에 서비스 제공 서버는 클라이언트 요청을 계속 수신  3. 마스터-슬레이브 패턴 (Master-slave pattern) 서비스 주체가 Master와 Slave로 구성됩니다. 마스터 컴포넌트는 슬래이브 컴포넌트간에 작업을 분배하고 슬래이가 반환한 결과로부터 최종 결과를 계산합니다.\n(1) 데이터베이스 복제\n\r4. 파이프-필터 패턴 (Pipe-filter pattern) 데이터스트림을 생성하고 가공하는 시스템을 구성하는데 사용할 수 있습니다. 각 단계는 필터 구성 요소로 구분되고 처리 데이터는 파이프를 통해 전달됩니다.\n(1) 컴파일러\n\r5. 브로커 패턴 (Broker pattern) 분리된 구성 요소가 있는 분산 시스템을 구성하는데 사용됩니다. 원격 서비스 호출을 통해 서로 상호작용할 수 있습니다. 브로커 구성 요소는 구성 요소간의 통신을 담당합니다.\n(1) Apache ActiveMQ\n(2) Apache Kafka\n(3) RabbitMQ\n\r6. 피어 투 피어 패턴 (Peer-to-peer pattern) 개별 구성요소는 피어로 표현하며, 각 피어는 다른 피어에게 서비스를 요청하는 클라이언트와 다른 피어에게 서비스를 제공하는 서버역할을 모두 할 수 있습니다.\n(1) 파일 공유 네트워크(Gnutella)\n(2) 블록체인 기반 상품\n\r7. 이벤트-버스 패턴 (Event-bus pattern) 이벤트 소스, 이벤트 리스터, 채널 및 이벤트 버스 4가지 구성요소로 구성됩니다. 소스는 이벤트 버스의 특정 채널에 메시지를 게시합니다. 청취자는 특정 채널을 구독합니다. 리스너트 이전에 구독한 채널에 게시된 메시지에 대한 알림을 받습니다.\n(1) 안드로이드 개발\n(2) 알림서비스\n\r8. 모델-뷰-컨트롤러 패턴 (Model-view-controller pattern) MVC 패턴으로 불리며 대화형 애플리케이션을 구성하는데 사용됩니다.\n Model : 핵심 기능 및 데이터 View : 사용자에게 정보를 표시 Controller : 사용자의 입력을 처리  (1) 웹 애플리케이션을 위한 아키텍처로 사용\n\r9. 블랙보드 패턴 (Blackboard pattern) 이 패턴은 솔루션이 결정되지 않은 문제에 유용합니다.\n blackboard : 솔루션 공간의 객체를 포함하는 구조화된 전역 메모리 지식 소스 : 고유한 표현이 있는 특수 모듈 제어 구성 요소 : 모듈을 선택하고 구성 및 실행합니다.  (1) 음성 인식\n(2) 차량 식별 및 추적\n\r10. 인터프리터 패턴 (Interpreter pattern) 이 패턴은 전용 언어로 작성된 프로그램을 해석하는 구성 요소를 설계하는데 사용됩니다. 기본 아이디어는 언어의 각 기호에 대한 클래스를 구성하는것입니다.\n(1) SQL과 같은 데이터베이스 쿼리 언어\n(2) 통신 프로토콜에 사용\n\r"
},
{
	"uri": "https://hnc-hskim.github.io/workshop/msa/software-architecture/",
	"title": "Software Architecture",
	"tags": [],
	"description": "",
	"content": "References  [참고1] https://dev.to/zachgoll/introduction-to-software-architecture-monolithic-vs-layered-vs-microservices-452 [참고2] https://github.com/mermaid-js/mermaid Diagram Editor  \u0026ldquo;Any intelligent fool can make things bigger, more complex, and more violent. It takes a touch of genius—and a lot of courage to move in the opposite direction\u0026rdquo;\n[From E.F. Schumacher\u0026rsquo;s book Small is Beautiful]\n\r1. 소프트웨어 아키텍처 소프트웨어 구조 또는 소프트웨어 아키텍처(software architecture)는 소프트웨어의 구성요소들 사이에서 유기적 관계를 표현하고 소프트웨어의 설계와 업그레이드를 통제하는 지침과 원칙이다.\n1.1 소프트웨어 아키텍처 설계시 고려사항  성능: 회전하는 \u0026ldquo;로드 중\u0026rdquo; 아이콘이 사라지기 전에 얼마나 기다려야 합니까? 가용성: 시스템이 실행되는 시간의 백분율은 무엇입니까? 사용성: 사용자가 시스템의 인터페이스를 쉽게 파악할 수 있습니까? 수정 가능성: 개발자가 시스템에 기능을 추가하려는 경우 수행하기 쉽습니까? 상호 운용성: 시스템이 다른 시스템과 원활하게 작동합니까? 보안: 시스템 주변에 보안 포트리스가 있습니까? 이식성: 시스템이 다양한 플랫폼(예: Windows, Mac, Linux)에서 실행될 수 있습니까? 확장성: 사용자 기반을 빠르게 성장시키면 시스템이 새로운 트래픽을 충족하도록 쉽게 확장할 수 있습니까? 배포 가능성: 프로덕션 환경에 새로운 기능을 추가하는 것이 쉽습니까? 안전: 소프트웨어가 물리적 사물을 제어하는 ​​경우 실제 사람에게 위험합니까?  2. 소프트웨어 아키텍처가 프로젝트의 성공에 중요한 13가지 이유 원문\r번역\r\r1. An architecture will inhibit or enable a system’s driving quality attributes. 2. The decisions made in an architecture allow you to reason about and manage change as the system evolves. 3. The analysis of an architecture enables early prediction of a system’s qualities. 4. A documented architecture enhances communication among stakeholders. 5. The architecture is a carrier of the earliest and hence most fundamental, hardest-to-change design decisions. 6. An architecture defines a set of constraints on subsequent implementation. 7. The architecture dictates the structure of an organization, or vice versa. 8. An architecture can provide the basis for evolutionary prototyping. 9. An architecture is the key artifact that allows the architect and project manager to reason about cost and schedule. 10. An architecture can be created as a transferable, reusable model that forms the heart of a product line. 11. Architecture-based development focuses attention on the assembly of components, rather than simply on their creation. 12. By restricting design alternatives, architecture channels the creativity of developers, reducing design and system complexity. 13. An architecture can be the foundation for training a new team member \r\r1. 아키텍처는 시스템의 구동 품질 속성을 억제하거나 활성화합니다. 2. 아키텍처에서 내린 결정을 통해 시스템이 발전함에 따라 변경 사항을 추론하고 관리할 수 있습니다. 3. 아키텍처 분석을 통해 시스템 품질을 조기에 예측할 수 있습니다. 4. 문서화된 아키텍처는 이해 관계자 간의 의사 소통을 향상시킵니다. 5. 아키텍처는 가장 초기에 가장 기본적이고 가장 변경하기 어려운 설계 결정의 전달자입니다. 6. 아키텍처는 후속 구현에 대한 일련의 제약 조건을 정의합니다. 7. 아키텍처는 조직의 구조를 결정하거나 그 반대의 경우도 마찬가지입니다. 8. 아키텍처는 진화적 프로토타이핑의 기초를 제공할 수 있습니다. 9. 아키텍처는 건축가와 프로젝트 관리자가 비용과 일정에 대해 추론할 수 있도록 하는 핵심 아티팩트입니다. 10. 아키텍처는 제품 라인의 핵심을 형성하는 양도 가능하고 재사용 가능한 모델로 생성될 수 있습니다. 11. 아키텍처 기반 개발은 단순히 구성 요소를 만드는 것보다 구성 요소의 조립에 주의를 집중합니다. 12. 설계 대안을 제한함으로써 아키텍처는 개발자의 창의성을 전달하여 설계 및 시스템 복잡성을 줄입니다. 13. 아키텍처는 새로운 팀원을 교육하기 위한 기반이 될 수 있습니다. \r\r\r\r\r"
},
{
	"uri": "https://hnc-hskim.github.io/workshop/",
	"title": "Workshops",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://hnc-hskim.github.io/workshop/spring/",
	"title": "Spring",
	"tags": [],
	"description": "",
	"content": "\r스프링 프레임워크(Spring Framework)는 오늘날 Java 기반 웹 애플리케이션 개발의 표준으로 인식되고 있습니다. 스프링 프레임워크를 기반으로 한 다수의 상용 프레임워크가 출시되었고, 스프링과 함께 많은 발전을 이뤄냈습니다. 이같은 상황에서 스프링 프로젝트는 더욱 향상된 개발 환경을 제공하기 위해 스프링 부트(Spring Boot), 보안 및 인증 모듈 등을 추가하였고, 새로운 기술을 지원하고자 다양한 서브 프로젝트를 개발해오고 있습니다.\n\r1. Springboot : 소개 2. Springboot : gradle 빌드 "
},
{
	"uri": "https://hnc-hskim.github.io/workshop/eventstorming/miro/",
	"title": "Event Storming",
	"tags": [],
	"description": "",
	"content": "References  [miro] https://miro.com/app/dashboard/ [test board] https://miro.com/app/board/uXjVOh72El0=/?share_link_id=330360109631  Event Storming hancomcloud test board\n"
},
{
	"uri": "https://hnc-hskim.github.io/workshop/msa/glossary/",
	"title": "Glossary",
	"tags": [],
	"description": "",
	"content": "용어 정리 A\n\rAWS AWS(Amazon Web Services)는 아마존닷컴의 클라우드 컴퓨팅 사업부이며 현재 클라우드 컴퓨팅 분야에서 압도적인 세계 1위를 차지하고 있으며 2022년부로 16주년을 맞는 다국적 기업이자 역사상 가장 큰 IT 및 클라우드 기업 중 하나이다. 아마존 웹 서비스는 다른 웹 사이트나 클라이언트측 응용 프로그램에 대해 온라인 서비스를 제공하고 있다. 이러한 서비스의 상당수는 최종 사용자에 직접 공개되는 것이 아니고, 다른 개발자가 사용 가능한 기능을 제공하는 플랫폼을 제공하는 PaaS이다.\nAPI Gateway API 게이트웨이 는 실제 백엔드 서비스 또는 데이터와 접속하고 API 호출에 대한 정책, 인증 및 일반 액세스 제어를 적용하여 중요한 데이터를 보호하는 트래픽 관리자입니다. API 게이트웨이는 백엔드 시스템 및 서비스에 대한 액세스를 제어하는 방법이며 외부 클라이언트와 백엔드 서비스 간의 통신을 최적화하여 클라이언트에게 원활한 경험을 제공하도록 설계되었습니다. API 게이트웨이는 서비스의 확장성과 고가용성을 보장합니다. 요청을 적절한 서비스로 라우팅하고 요청자에게 응답을 다시 보내는 기능을 담당합니다.\nD\n\rRelational Database 관계형 데이터베이스(Relational Database)로 풀이되는 RDB는 말 그대로 관계형 모델을 기반으로 하는 데이터베이스이다. 이를 유지하고 관리하기 위한 시스템을 RDBMS (Relational Database Management System) 이라고 부른다.\n 2차원 데이터로 표현된다 (행/열) 상호관련성을 가진 테이블의 집합으로 구성된다 테이블 사이의 관계를 외래키로 나타낸다 스키마 변경이 어렵다 Vertical Scalable 하지만, Horizontal scale은 어렵다 메인테넌스 코스트 / 사용 요금이 비싸다 SQL을 사용해 데이터를 질의한다 ACID 성질을 갖는다  NoSQL Database Non-SQL 이라고도 하고, Not only SQL 의 약자라고도 한다. 관계형이 아닌 데이터 모델을 총칭하고, 도큐먼트 모델 / 키-값 모델 / 그래프 모델 / 와이드 컬럼 모델 등 다양한 데이터 모델이 있다.\n 양한 방식으로 데이터를 표현한다 테이블(혹은 컬렉션 혹은 또 다른 명칭) 사이에 딱히 명시된 제약이나 규칙이 없다 스키마가 고정적이지 않고, 매우 유연하다 Horizontal Scale이 쉽다 코스트 저렴 / 오픈소스도 많다 연산이 빠르고 빅데이터 \u0026amp; 실시간 연산에 적합하다  도큐먼트 모델은 레코드 하나를 오브젝트(도큐먼트) 형식으로 표현한다. 자유로운 스키마 구조를 가지며 구조가 확정되지 않은 데이터를 밀어넣고, 자유롭게 작업하기 좋다. (MongoDB) 그래프 모델은 데이터를 버텍스와 엣지로 그래프에 표현하는 방식이다. 데이터 사이의 유기적인 관계를 표현하기에 적합하다. (Neo4j) 키/값 모델은 하나의 키에 값을 맵핑하는 해시 구조의 데이터 모델이다. 빠르게 데이터에 접근할 수 있는 장점이 있다. (redis) 와이드 컬럼 모델은 테이블 형태를 취하지만 행마다 갖는 컬럼의 형태가 고정되어 있지 않은 데이터 모델이다.\nF\n\rFaaS FaaS(Function-as-a-Service)는 개발자가 자체 인프라를 유지관리할 필요 없이 애플리케이션 패키지를 기능으로 빌드, 실행, 관리할 수 있게 해주는 일종의 클라우드 컴퓨팅 서비스입니다.\nK\n\rkafka Apache Kafka(아파치 카프카)는 LinkedIn에서 개발된 분산 메시징 시스템이다. 대용량 실시간 로그처리에 특화되어 기존 메시징 시스템보다 TPS(Transaction per Second)가 우수하다. 서비스 제공자가 퍼블리시(Publish)한 이벤트를, 필요한 소비자가 구독(Subscribe)하여 활용하는 Pub/Sub 기반 아키텍처가 특징이다.\nL\n\rLoad Balancer 로드밸런서는 서버에 가해지는 부하(=로드)를 분산(=밸런싱)해주는 장치 또는 기술을 통칭한다. 클라이언트와 서버풀(Server Pool, 분산 네트워크를 구성하는 서버들의 그룹) 사이에 위치하며, 한 대의 서버로 부하가 집중되지 않도록 트래픽을 관리해 각각의 서버가 최적의 퍼포먼스를 보일 수 있도록 해준다.\n L4 로드밸런서는 네트워크 계층(IP, IPX)이나 트랜스포트 계층(TCP, UDP)의 정보를 바탕으로 로드를 분산한다. IP주소나 포트번호, MAC주소, 전송 프로토콜에 따라 트래픽을 나누는 것이 가능하다. L7 로드밸런서의 경우 애플리케이션 계층(HTTP, FTP, SMTP)에서 로드를 분산하기 때문에 HTTP 헤더, 쿠키 등과 같은 사용자의 요청을 기준으로 특정 서버에 트래픽을 분산하는 것이 가능하다.  M\n\rMonolithic MSA와 반대되는 개념으로 설명하기 위한 전통적인 아키텍처를 지칭, 소프트웨어의 모든 구성요소가 한 프로젝트에 통합 되어 있는 형태\nMSA MicroService Architecture 마이크로서비스 아키텍처에 대한 정확한 정의는 없다. 하지만 마이크로서비스란 작고, 독립적으로 배포 가능한 각각의 기능을 수행하는 서비스로 구성된 프레임워크라고 할 수 있다. 마이크로서비스는 완전히 독립적으로 배포가 가능하고, 다른 기술 스택(개발 언어, 데이터베이스 등)이 사용 가능한 단일 사업 영역에 초점을 둔다.\nMaven Maven은 자바용 프로젝트 관리도구로 Apache Ant의 대안으로 만들어졌다. 프로젝트의 작성부터 컴파일, 페트스 등 프로젝트 라이프사이클에 포함되는 각 테스트를 지원해 준다.\nR\n\rRegion 아마존 웹 서비스의 데이터 센터를 리전(region)이라고 부른다.\n 아시아 태평양 (6개 리전)  아시아 태평양 (도쿄), 일본 아시아 태평양 (서울), 대한민국 아시아 태평양 (싱가포르) 아시아 태평양 (뭄바이), 인도 아시아 태평양 (시드니), 오스트레일리아 중국 (베이징)    S\n\rSoftware Architecture 소프트웨어 구조 또는 소프트웨어 아키텍처(software architecture)는 소프트웨어의 구성요소들 사이에서 유기적 관계를 표현하고 소프트웨어의 설계와 업그레이드를 통제하는 지침과 원칙이다.\nStrangler pattern 특정 기능을 새로운 애플리케이션 및 서비스로 점진적으로 교체하여 레거시 시스템을 단계적으로 마이그레이션한다. 레거시 시스템의 기능이 교체되면 결국 새 시스템이 기존 시스템의 모든 기능을 대체하여 기존 시스템을 중단하고 서비스 해제할 수 있다. 백 엔드 애플리케이션을 새로운 아키텍처로 점진적으로 마이그레이션하는 경우 이 패턴을 사용한다.\n다음 경우에는 이 패턴이 적합하지 않을 수 있다.\n 백 엔드 시스템에 대한 요청을 가로챌 수 없는 경우 대량 교체의 복잡성이 낮은 소규모 시스템의 경우  Scale-Up 서버 자체의 성능을 확장하는 것을 의미한다.\nex) CPU를 i3 -\u0026gt; i7으로 업그레이드\nScale-Out 기존 서버와 동일하거나 낮은 성능의 서버를 두 대 이상 증설하여 운영하는 것을 의미한다.\n"
},
{
	"uri": "https://hnc-hskim.github.io/workshop/ide/code-server/",
	"title": "Code Server",
	"tags": [],
	"description": "",
	"content": "References  [coder] https://coder.com/ [code server] https://github.com/coder/code-server  Coder is an open source platform for creating and managing developer workspaces on your preferred clouds and servers. By building on top of common development interfaces (SSH) and infrastructure tools (Terraform), Coder aims to make the process of provisioning and accessing remote workspaces approachable for organizations of various sizes and stages of cloud-native maturity.\n\rWEB-IDE 사용법 1. 차트 설치  Rancher 접속(Apps -\u0026gt; Charts 선택) Chart Repository(code-server 선택) code-server 차트 선택   2. 차트 선택  우측 상단의 Install 버튼 클릭   3. 이름 입력  Namespace와 Name 입력후 Next 버튼 클릭   4. 차트 values 수정  접속 URL 수정 및 패스워드 변경(기본 password : code) \u0026ldquo;이름\u0026rdquo;.apps.orca.cloud.hancom.com 사용할것 수정후 Install 버큰 클릭   5. 설치  Output 창에 SUCCESS 나올때까지 대기(약 1분 소요)   6. 웹 브라우저에서 확인  접속 URL을 웹브라우져에서 입력   7. kubectl 동작 확인  터미널 창에서 kubectl cli 동작 확인   "
},
{
	"uri": "https://hnc-hskim.github.io/blazor/",
	"title": "Blazors",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://hnc-hskim.github.io/blazor/lab/wpf-blazor-1/",
	"title": "Wpf Blazor 1",
	"tags": [],
	"description": "",
	"content": "References  WPF Blazor 앱 빌드   WPF Blazor 앱 프로젝트 만들기 프로젝트에 Razor 구성 요소 추가 Windows에서 앱 실행  Blazor Hybrid가 GA(일반 공급)에 도달했으며 프로덕션 워크로드에 대해 완전히 지원됩니다. Visual Studio 및 Mac용 Visual Studio는 Blazor Hybrid 앱 작업을 위해 시험판 버전으로 제공되며 최종 릴리스 전에 수정될 수 있습니다. 최상의 도구 환경을 위해 Visual Studio 2022 미리 보기를 업데이트된 상태로 유지하는 것이 좋습니다.\n\r요구사항  visual studio 2022 visual studio workload(.net desktop development)  WPF Blazor 프로젝트 만들기   visual studio 2022 preview 시작   새 프로젝트 만들기 선택   wpf 애플리케이션 선택   이름(WpfBlazor) 입력 및 저장 위치 선택   .NET 6.0(장기 지원) 선택   NuGet 패키지 관리자 실행   (Microsoft.AspNetCore.Components.WebView.Wpf 패키지 설치)   프로젝트 파일 편집(WpfBlazor 프로젝트 우클릭하여 프로젝트 파일 편집 선택)  SDK를 Microsoft.NET.Sdk.Razor로 변경 WpfBlazor루트 네임스페이스 추가 변경내용 저장  \u0026lt;Project Sdk=\u0026#34;Microsoft.NET.Sdk.Razor\u0026#34;\u0026gt;\r\u0026lt;PropertyGroup\u0026gt;\r\u0026lt;RootNameSpace\u0026gt;WpfBlazor\u0026lt;/RootNameSpace\u0026gt;\r\u0026lt;OutputType\u0026gt;WinExe\u0026lt;/OutputType\u0026gt;\r\u0026lt;TargetFramework\u0026gt;net6.0-windows\u0026lt;/TargetFramework\u0026gt;\r\u0026lt;Nullable\u0026gt;enable\u0026lt;/Nullable\u0026gt;\r\u0026lt;UseWPF\u0026gt;true\u0026lt;/UseWPF\u0026gt;\r\u0026lt;/PropertyGroup\u0026gt;\r\u0026lt;ItemGroup\u0026gt;\r\u0026lt;PackageReference Include=\u0026#34;Microsoft.AspNetCore.Components.WebView.Wpf\u0026#34; Version=\u0026#34;6.0.419\u0026#34; /\u0026gt;\r\u0026lt;/ItemGroup\u0026gt;\r\u0026lt;/Project\u0026gt; _Imports.razor 파일 추가(위치 프로젝트 루트) @using Microsoft.AspNetCore.Components.Web wwwroot 폴더 추가  index.html 추가  \u0026lt;!DOCTYPE html\u0026gt;\r\u0026lt;html lang=\u0026#34;en\u0026#34;\u0026gt;\r\u0026lt;head\u0026gt;\r\u0026lt;meta charset=\u0026#34;utf-8\u0026#34; /\u0026gt;\r\u0026lt;meta name=\u0026#34;viewport\u0026#34; content=\u0026#34;width=device-width, initial-scale=1.0\u0026#34; /\u0026gt;\r\u0026lt;title\u0026gt;WpfBlazor\u0026lt;/title\u0026gt;\r\u0026lt;base href=\u0026#34;/\u0026#34; /\u0026gt;\r\u0026lt;link href=\u0026#34;css/bootstrap/bootstrap.min.css\u0026#34; rel=\u0026#34;stylesheet\u0026#34; /\u0026gt;\r\u0026lt;link href=\u0026#34;css/app.css\u0026#34; rel=\u0026#34;stylesheet\u0026#34; /\u0026gt;\r\u0026lt;link href=\u0026#34;WpfBlazor.styles.css\u0026#34; rel=\u0026#34;stylesheet\u0026#34; /\u0026gt;\r\u0026lt;/head\u0026gt;\r\u0026lt;body\u0026gt;\r\u0026lt;div id=\u0026#34;app\u0026#34;\u0026gt;Loading...\u0026lt;/div\u0026gt;\r\u0026lt;div id=\u0026#34;blazor-error-ui\u0026#34;\u0026gt;\rAn unhandled error has occurred.\r\u0026lt;a href=\u0026#34;\u0026#34; class=\u0026#34;reload\u0026#34;\u0026gt;Reload\u0026lt;/a\u0026gt;\r\u0026lt;a class=\u0026#34;dismiss\u0026#34;\u0026gt;🗙\u0026lt;/a\u0026gt;\r\u0026lt;/div\u0026gt;\r\u0026lt;script src=\u0026#34;_framework/blazor.webview.js\u0026#34;\u0026gt;\u0026lt;/script\u0026gt;\r\u0026lt;/body\u0026gt;\r\u0026lt;/html\u0026gt; wwwroot/css/app.css 파일 추가 html, body {\rfont-family: \u0026#39;Helvetica Neue\u0026#39;, Helvetica, Arial, sans-serif;\r}\r.valid.modified:not([type=checkbox]) {\routline: 1px solid #26b050;\r}\r.invalid {\routline: 1px solid red;\r}\r.validation-message {\rcolor: red;\r}\r#blazor-error-ui {\rbackground: lightyellow;\rbottom: 0;\rbox-shadow: 0 -1px 2px rgba(0, 0, 0, 0.2);\rdisplay: none;\rleft: 0;\rpadding: 0.6rem 1.25rem 0.7rem 1.25rem;\rposition: fixed;\rwidth: 100%;\rz-index: 1000;\r}\r#blazor-error-ui .dismiss {\rcursor: pointer;\rposition: absolute;\rright: 0.75rem;\rtop: 0.5rem;\r} Counter.razor 파일 추가 \u0026lt;h1\u0026gt;Counter\u0026lt;/h1\u0026gt;\r\u0026lt;p\u0026gt;Current count: @currentCount\u0026lt;/p\u0026gt;\r\u0026lt;button class=\u0026#34;btn btn-primary\u0026#34; @onclick=\u0026#34;IncrementCount\u0026#34;\u0026gt;Click me\u0026lt;/button\u0026gt;\r@code {\rprivate int currentCount = 0;\rprivate void IncrementCount()\r{\rcurrentCount++;\r}\r} MainWindow.xaml 파일 수정 \u0026lt;Window x:Class=\u0026#34;WpfBlazor.MainWindow\u0026#34;\rxmlns=\u0026#34;http://schemas.microsoft.com/winfx/2006/xaml/presentation\u0026#34;\rxmlns:x=\u0026#34;http://schemas.microsoft.com/winfx/2006/xaml\u0026#34;\rxmlns:d=\u0026#34;http://schemas.microsoft.com/expression/blend/2008\u0026#34;\rxmlns:mc=\u0026#34;http://schemas.openxmlformats.org/markup-compatibility/2006\u0026#34;\rxmlns:blazor=\u0026#34;clr-namespace:Microsoft.AspNetCore.Components.WebView.Wpf;assembly=Microsoft.AspNetCore.Components.WebView.Wpf\u0026#34;\rxmlns:local=\u0026#34;clr-namespace:WpfBlazor\u0026#34;\rmc:Ignorable=\u0026#34;d\u0026#34;\rTitle=\u0026#34;MainWindow\u0026#34; Height=\u0026#34;450\u0026#34; Width=\u0026#34;800\u0026#34;\u0026gt;\r\u0026lt;Grid\u0026gt;\r\u0026lt;blazor:BlazorWebView HostPage=\u0026#34;wwwroot\\index.html\u0026#34; Services=\u0026#34;{DynamicResource services}\u0026#34;\u0026gt;\r\u0026lt;blazor:BlazorWebView.RootComponents\u0026gt;\r\u0026lt;blazor:RootComponent Selector=\u0026#34;#app\u0026#34; ComponentType=\u0026#34;{x:Type local:Counter}\u0026#34; /\u0026gt;\r\u0026lt;/blazor:BlazorWebView.RootComponents\u0026gt;\r\u0026lt;/blazor:BlazorWebView\u0026gt;\r\u0026lt;/Grid\u0026gt;\r\u0026lt;/Window\u0026gt; MainWindow.cs 파일 수정 using System;\rusing System.Collections.Generic;\rusing System.Linq;\rusing System.Text;\rusing System.Threading.Tasks;\rusing System.Windows;\rusing System.Windows.Controls;\rusing System.Windows.Data;\rusing System.Windows.Documents;\rusing System.Windows.Input;\rusing System.Windows.Media;\rusing System.Windows.Media.Imaging;\rusing System.Windows.Navigation;\rusing System.Windows.Shapes;\rusing Microsoft.Extensions.DependencyInjection;\rnamespace WpfBlazor\r{\r/// \u0026lt;summary\u0026gt;\r/// Interaction logic for MainWindow.xaml\r/// \u0026lt;/summary\u0026gt;\rpublic partial class MainWindow : Window\r{\rpublic MainWindow()\r{\rInitializeComponent();\rvar serviceCollection = new ServiceCollection();\rserviceCollection.AddWpfBlazorWebView();\rResources.Add(\u0026#34;services\u0026#34;, serviceCollection.BuildServiceProvider());\r}\r}\r} 앱 실행 "
},
{
	"uri": "https://hnc-hskim.github.io/cloud/",
	"title": "Clouds",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://hnc-hskim.github.io/cloud/helm/helm-repository/",
	"title": "Helm Repository",
	"tags": [],
	"description": "",
	"content": "Github에 helm repository 만들기 1. Github으로 이동 2. New 버튼을 클릭한다.  Repository name(helm-charts) Public 체크 Add a README file 체크   3. 생성된 Repository 화면 4. 접근 URL 셋팅   리파지터리 홈 탭 메뉴의 Settings를 선택한다.\n  좌측 메뉴에 Pages를 선택한다.   main 브랜치를 선택후 save 버튼을 클릭한다.   publicshed 주소가 나오는데 이 주소가 helm repository 주소가 된다.   5. Local Repository 만들기  생성한 Repository를 로컬에 clone한다.  $ git clone https://github.com/\u0026#34;Your github id\u0026#34;/helm-charts.git\r$ cd helm-charts\r# stable 디렉토리를 생성한다. $ mkdir stable 6. 아래 samples Repository를 로컬에 clone한다. helm sample Github\n 차트 검증  $ cd samples\\sftp-server\\\r$ helm lint\r==\u0026gt; Linting .\r[INFO] Chart.yaml: icon is recommended\r1 chart(s) linted, 0 chart(s) failed  helm차트를 패키징한다.  $ cd samples\r$ helm package .\\sftp-server\\\rSuccessfully packaged chart and saved it to: C:\\work2022\\git\\hnc-hskim\\samples\\sftp-server-0.3.2.tgz  만들어진 sftp-server-0.3.2.tgz 파일을 Helm Local Repository에 복사한다.  cp sftp-server-0.3.2.tgz \u0026#34;your helm chart local repo\u0026#34;/statble/sftp-server-0.3.2.tgz  helm chart local repository에서 아래 명령으로 index.yaml파일을 새로 만든다.  #helm repo index stable/ --url https://\u0026#34;Your github id\u0026#34;.github.io/helm-charts/stable\r# helm-chart 리파지터리 root에서 실행\r#helm repo index ./stable\r#helm repo index ./code-server 7. 작업 내용을 commit 한다. $ git add . \u0026amp;\u0026amp; git commit -m \u0026#34;init helm charts\u0026#34; \u0026amp;\u0026amp; git push origin main 7. Helm Repository 추가  작업 내용을 commit하면 git actions에 의해 Github Pages가 빌드후 배포된다.  $ helm repo add github-stable https://\u0026#34;Your github id\u0026#34;.github.io/helm-charts/stable\r\u0026#34;github-stable\u0026#34; has been added to your repositories  helm repository 확인  $ helm repo list\rNAME URL github-stable https://hnc-hskim.github.io/helm-charts/stable\r$ helm search repo sftp-server\rNAME CHART VERSION APP VERSION DESCRIPTION\rgithub-stable/sftp-server 0.3.2 1.0 A helm chart for a SFTP server 8. 배포 $ helm repo update\rHang tight while we grab the latest from your chart repositories...\r...Successfully got an update from the \u0026#34;github-stable\u0026#34; chart repository Update Complete. ⎈Happy Helming!⎈\r$ kubectl create namespace sftp\rnamespace/sftp created\r$ helm install --generate-name github-stable/sftp-server --namespace sftp\rNAME: sftp-server-1658462580\rLAST DEPLOYED: Fri Jul 22 13:03:01 2022\rNAMESPACE: sftp\rSTATUS: deployed\rREVISION: 1\rTEST SUITE: None\rNOTES:\r1. Get the application URL by running these commands:\rexport POD_NAME=$(kubectl get pods --namespace sftp -l \u0026#34;app.kubernetes.io/name=sftp-server,app.kubernetes.io/instance=sftp-server-1658462580\u0026#34; -o jsonpath=\u0026#34;{.items[0].metadata.name}\u0026#34;)\recho \u0026#34;Visit http://127.0.0.1:8080 to use your application\u0026#34;\rkubectl port-forward $POD_NAME 8080:80  values.yaml 수정 및 사용  $ helm inspect values github-stable/sftp-server \u0026gt;\u0026gt; values.yaml\r# values.yaml 파일을 열고 ingress 섹션을 수정한다.\ringress:\renabled: true\rclassName: \u0026#34;\u0026#34;\rannotations: {}\r# kubernetes.io/ingress.class: nginx\r# kubernetes.io/tls-acme: \u0026#34;true\u0026#34;\rhosts:\r- host: chart-example.local\rpaths:\r- path: /\rpathType: ImplementationSpecific\rtls: []\r# - secretName: chart-example-tls\r# hosts:\r# - chart-example.local\r# 수정한 values.yaml 파일을 이용하여 helm 배포\r$ helm install -f values.yaml --generate-name github-stable/sftp-server --namespace sftp 9. 삭제 $ helm ls -n sftp\rNAME NAMESPACE REVISION UPDATED STATUS CHART APP VERSION\rsftp-server-1658462580 sftp 1 2022-07-22 13:03:01.7682638 +0900 KST deployed sftp-server-0.3.2 1.0 $ helm delete sftp-server-1658462580 -n sftp\rrelease \u0026#34;sftp-server-1658462580\u0026#34; uninstalled 10. Local Helm Repository 구성 \rgit submodule add -b main https://github.com/hnc-hskim/helm-charts.git packages "
},
{
	"uri": "https://hnc-hskim.github.io/cloud/rancher/monitoring/",
	"title": "Monitoring",
	"tags": [],
	"description": "",
	"content": "Rancher에 모니터링 도구 설치 및 GPU 모니터링 References  [참고1] https://nvidia.github.io/gpu-monitoring-tools/ [참고2] https://passwd.tistory.com/entry/NVIDIAgpu-monitoring-tools-dcgm-exporter-CrashLoopBackOff  rancher에서 monitoring 도구 설치   Apps -\u0026gt; Charts 이동후 monitoring 검색   Monitoring 설치 설치를 진행하면 모니터링 앱은 Rancher 의 cattle-monitoring-system namespace 에 배포됨\n(설치후 랜처 로그아웃후 다시 로그인)\n  네비게이션 영역을 보면 Monitoring 메뉴가 추가되어 있음   대쉬보드 확인   grafana 확인   그라파나에 로그인합니다. Grafana 인스턴스의 기본 관리자 사용자 이름과 비밀번호는 입니다 admin/prom-operator. (비밀번호가 있는 사람에 관계없이 Rancher의 클러스터 관리자 권한은 여전히 ​​Grafana 인스턴스에 액세스해야 합니다.) 차트를 배포하거나 업그레이드할 때 대체 자격 증명을 제공할 수도 있습니다.\n\rGPU 노드 모니터링을 위한 dcgm-exporter 설치  Helm v3 설치  curl -fsSL -o get_helm.sh https://raw.githubusercontent.com/helm/helm/master/scripts/get-helm-3 \u0026amp;\u0026amp; \\\rchmod 700 get_helm.sh \u0026amp;\u0026amp; \\\r./get_helm.sh  Helm 저장소 설정  helm repo add gpu-helm-charts \\\rhttps://nvidia.github.io/gpu-monitoring-tools/helm-charts  레파지터리 업데이트  helm repo update  DCGM-Exporter 공식 차트 설치  #helm install --generate-name gpu-helm-charts/dcgm-exporter\r# orca mlops node를 모니터링하기 위해 tolerations, nodeSelector 수정한 values파일로 설치한다. helm install -f dcgm-values.yaml --generate-name gpu-helm-charts/dcgm-exporter  차트 확인  $ helm search repo gpu-helm-charts\rNAME CHART VERSION APP VERSION DESCRIPTION\rgpu-helm-charts/dcgm-exporter 2.4.0 2.4.0 A Helm chart for DCGM exporter\rgpu-helm-charts/kube-prometheus 0.0.43 Manifests, dashboards, and alerting rules for e...\rgpu-helm-charts/prometheus-operator 0.0.15 Provides easy monitoring definitions for Kubern...\r$ helm inspect chart gpu-helm-charts/dcgm-exporter apiVersion: v2\rappVersion: 2.4.0\rdescription: A Helm chart for DCGM exporter\rhome: https://github.com/nvidia/gpu-monitoring-tools/\ricon: https://assets.nvidiagrid.net/ngc/logos/DCGM.png\rkeywords:\r- gpu\r- cuda\r- compute\r- monitoring\r- telemetry\r- tesla\rkubeVersion: \u0026#39;\u0026gt;= 1.13.0-0\u0026#39;\rname: dcgm-exporter\rsources:\r- https://gitlab.com/nvidia/container-toolkit/gpu-monitoring-tools\rversion: 2.4.0  dcgm-values.yaml로 저장한다.  $ helm inspect values gpu-helm-charts/dcgm-exporter # Copyright (c) 2020, NVIDIA CORPORATION. All rights reserved.\r#\r# Licensed under the Apache License, Version 2.0 (the \u0026#34;License\u0026#34;);\r# you may not use this file except in compliance with the License.\r# You may obtain a copy of the License at\r#\r# http://www.apache.org/licenses/LICENSE-2.0\r#\r# Unless required by applicable law or agreed to in writing, software\r# distributed under the License is distributed on an \u0026#34;AS IS\u0026#34; BASIS,\r# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r# See the License for the specific language governing permissions and\r# limitations under the License.\rimage:\rrepository: nvcr.io/nvidia/k8s/dcgm-exporter\rpullPolicy: IfNotPresent\r# Image tag defaults to AppVersion, but you can use the tag key\r# for the image tag, e.g:\rtag: 2.2.9-2.4.0-ubuntu18.04\r# Comment the following line to stop profiling metrics from DCGM\rarguments: [\u0026#34;-f\u0026#34;, \u0026#34;/etc/dcgm-exporter/dcp-metrics-included.csv\u0026#34;]\r# NOTE: in general, add any command line arguments to arguments above\r# and they will be passed through.\r# Use \u0026#34;-r\u0026#34;, \u0026#34;\u0026lt;HOST\u0026gt;:\u0026lt;PORT\u0026gt;\u0026#34; to connect to an already running hostengine\r# Example arguments: [\u0026#34;-r\u0026#34;, \u0026#34;host123:5555\u0026#34;]\r# Use \u0026#34;-n\u0026#34; to remove the hostname tag from the output.\r# Example arguments: [\u0026#34;-n\u0026#34;]\r# Use \u0026#34;-d\u0026#34; to specify the devices to monitor. -d must be followed by a string\r# in the following format: [f] or [g[:numeric_range][+]][i[:numeric_range]]\r# Where a numeric range is something like 0-4 or 0,2,4, etc.\r# Example arguments: [\u0026#34;-d\u0026#34;, \u0026#34;g+i\u0026#34;] to monitor all GPUs and GPU instances or\r# [\u0026#34;-d\u0026#34;, \u0026#34;g:0-3\u0026#34;] to monitor GPUs 0-3.\rimagePullSecrets: []\rnameOverride: \u0026#34;\u0026#34;\rfullnameOverride: \u0026#34;\u0026#34;\rserviceAccount:\r# Specifies whether a service account should be created\rcreate: true\r# Annotations to add to the service account\rannotations: {}\r# The name of the service account to use.\r# If not set and create is true, a name is generated using the fullname template\rname:\rpodSecurityContext: {}\r# fsGroup: 2000\rsecurityContext:\rrunAsNonRoot: false\rrunAsUser: 0\rcapabilities:\radd: [\u0026#34;SYS_ADMIN\u0026#34;]\r# readOnlyRootFilesystem: true\rservice:\rtype: ClusterIP\rport: 9400\raddress: \u0026#34;:9400\u0026#34;\r# Annotations to add to the service\rannotations: {}\rresources: {}\r# limits:\r# cpu: 100m\r# memory: 128Mi\r# requests:\r# cpu: 100m\r# memory: 128Mi\rserviceMonitor:\renabled: true\rinterval: 15s\radditionalLabels: {}\r#monitoring: prometheus\rmapPodsMetrics: false\rnodeSelector: {}\r#node: gpu\rtolerations: []\r#- operator: Exists\raffinity: {}\r#nodeAffinity:\r# requiredDuringSchedulingIgnoredDuringExecution:\r# nodeSelectorTerms:\r# - matchExpressions:\r# - key: nvidia-gpu\r# operator: Exists\rextraHostVolumes: []\r#- name: host-binaries\r# hostPath: /opt/bin\rextraVolumeMounts: []\r#- name: host-binaries\r# mountPath: /opt/bin\r# readOnly: true\rextraEnv: []\r#- name: EXTRA_VAR\r# value: \u0026#34;TheStringValue\u0026#34;  helm 삭제  $ helm ls\rNAME NAMESPACE REVISION UPDATED STATUS CHART APP VERSION dcgm-exporter-1658202339 default 1 2022-07-19 12:45:40.1694572 +0900 KST deployed dcgm-exporter-2.4.0 2.4.0\r$ helm delete dcgm-exporter-1658202339 exporter 추가후 동작 확인 $ kubectl get pods -A | grep exporter cattle-monitoring-system rancher-monitoring-prometheus-node-exporter-6q7pp 1/1 Running 0 56m\rcattle-monitoring-system rancher-monitoring-prometheus-node-exporter-8bmpz 1/1 Running 0 56m\rcattle-monitoring-system rancher-monitoring-prometheus-node-exporter-8xrk6 1/1 Running 0 56m\rcattle-monitoring-system rancher-monitoring-prometheus-node-exporter-blvhr 1/1 Running 0 56m\rcattle-monitoring-system rancher-monitoring-prometheus-node-exporter-kc4ql 1/1 Running 0 56m\rcattle-monitoring-system rancher-monitoring-prometheus-node-exporter-l56nm 1/1 Running 0 56m\rcattle-monitoring-system rancher-monitoring-prometheus-node-exporter-qkk82 1/1 Running 0 56m\rcattle-monitoring-system rancher-monitoring-prometheus-node-exporter-s654d 1/1 Running 0 56m\rcattle-monitoring-system rancher-monitoring-prometheus-node-exporter-x6hjz 1/1 Running 0 56m\rdefault dcgm-exporter-1658202339-6wwlg 0/1 CrashLoopBackOff 6 5m22s\rdefault dcgm-exporter-1658202339-ffch6 0/1 CrashLoopBackOff 6 5m22s\rdefault dcgm-exporter-1658202339-kgldt 0/1 CrashLoopBackOff 7 5m22s\rdefault dcgm-exporter-1658202339-nprlc 0/1 CrashLoopBackOff 6 5m22s CrashLoopBackoff 상태 확인  로그는 정상  $ kubectl logs dcgm-exporter-1658205662-qwhs9\rtime=\u0026#34;2022-07-19T03:50:16Z\u0026#34; level=info msg=\u0026#34;Starting dcgm-exporter\u0026#34;\rtime=\u0026#34;2022-07-19T03:50:16Z\u0026#34; level=info msg=\u0026#34;DCGM successfully initialized!\u0026#34;\rtime=\u0026#34;2022-07-19T03:50:16Z\u0026#34; level=info msg=\u0026#34;Collecting DCP Metrics\u0026#34;\rtime=\u0026#34;2022-07-19T03:50:16Z\u0026#34; level=info msg=\u0026#34;Kubernetes metrics collection enabled!\u0026#34;\rtime=\u0026#34;2022-07-19T03:50:16Z\u0026#34; level=info msg=\u0026#34;Pipeline starting\u0026#34;\rtime=\u0026#34;2022-07-19T03:50:16Z\u0026#34; level=info msg=\u0026#34;Starting webserver\u0026#34;  상태 확인  $ kubectl describe pod dcgm-exporter-1658205662-qwhs9\r......\rEvents:\rType Reason Age From Message\r---- ------ ---- ---- -------\rNormal Scheduled 29m default-scheduler Successfully assigned default/dcgm-exporter-1658205662-qwhs9 to hcidc-sv-paz-orca-worker-09\rNormal Pulled 29m kubelet Container image \u0026#34;nvcr.io/nvidia/k8s/dcgm-exporter:2.2.9-2.4.0-ubuntu18.04\u0026#34; already present on machine\rNormal Created 29m kubelet Created container exporter\rNormal Started 29m kubelet Started container exporter\rWarning Unhealthy 28m (x3 over 29m) kubelet Readiness probe failed: HTTP probe failed with statuscode: 503 CrashLoopBackOff 해결 $ kubectl edit daemonset.apps/dcgm-exporter-1658205662\r# initialDelaySeconds를 60으로 변경\r.......\rlivenessProbe:\rfailureThreshold: 3\rhttpGet:\rpath: /health\rport: 9400\rscheme: HTTP\rinitialDelaySeconds: 60\rperiodSeconds: 5\rsuccessThreshold: 1\rtimeoutSeconds: 1 grafana로 이동후 gpu dashboard 설치 DCGM Exporter Dashboard 설치\rhttps://grafana.com/grafana/dashboards/12239   Import 선택   dashboard id(12239) 입력   Prometheus 선택   Dashboard 확인   "
},
{
	"uri": "https://hnc-hskim.github.io/terraform/introduction/",
	"title": "Introduction",
	"tags": [],
	"description": "",
	"content": "테라폼(Terraform)은 하시코프(Hashicorp)에서 오픈소스로 개발중인 클라우드 인프라스트럭처 자동화를 지향하는 코드로서의 인프라스트럭처(Infrastructure as Code), IaC1 도구입니다.\nAWS 클라우드 포메이션AWS CloudFormation의 경우 AWS만 지원하는 것과 달리 테라폼의 경우 아마존 웹 서비스, 구글 클라우드 플랫폼(Google Cloud Platform), 마이크로소프트 애저(Microsoft Azure)와 같은 주요 클라우드 서비스를 비롯한 다양한 클라우드 서비스들을 프로바이더 방식으로 제공하고 있습니다. 이를 통해 테라폼만으로 멀티 클라우드의 리소스들을 선언하고 코드로 관리하는 것도 가능합니다.\n테라폼은 고(Go) 프로그래밍 언어로 개발하고 있습니다.\n테라폼 공식 홈\nterraform unlock $ terraform force-unlock ec8fb402-fb9f-06c1-2bda-c300a7411d26\rDo you really want to force-unlock?\rTerraform will remove the lock on the remote state.\rThis will allow local Terraform commands to modify this state, even though it\rmay be still be in use. Only \u0026#39;yes\u0026#39; will be accepted to confirm.\rEnter a value: yes\rTerraform state has been successfully unlocked!\rThe state has been unlocked, and Terraform commands should now be able to\robtain a new lock on the remote state.   IaC는 코드로 인프라스트럭처를 관리한다는 개념으로 테라폼에서는 하시코프 설정 언어(HCL, Hashicorp Configuration Language)을 사용해 클라우드 리소스를 선언합니다.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n   "
},
{
	"uri": "https://hnc-hskim.github.io/terraform/",
	"title": "Terraforms",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://hnc-hskim.github.io/references/kubernetes/",
	"title": "Kubernetes",
	"tags": [],
	"description": "",
	"content": "참고  Advanced Scheduling  "
},
{
	"uri": "https://hnc-hskim.github.io/references/",
	"title": "References",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://hnc-hskim.github.io/references/terraform/",
	"title": "Terraform",
	"tags": [],
	"description": "",
	"content": "참고  helm values파일내 환경변수 전달 nginx controller acm 적용  "
},
{
	"uri": "https://hnc-hskim.github.io/hugo/comments/",
	"title": "Comments",
	"tags": [],
	"description": "",
	"content": "[참고] https://velog.io/@mellonggo/Github-%ED%8E%98%EC%9D%B4%EC%A7%80-%EB%B8%94%EB%A1%9C%EA%B7%B8-%EB%A7%8C%EB%93%A4%EA%B8%B0-with-Hugo\n댓글 기능 추가  리파지터리 생성  blog-comments로 리파지터리 생성  layouts/partials/custom-footer.html 파일 생성 및 스크립트 추가  테마별로 지정해야할 위치가 다를수 있다. learn 테마의 경우 post 레이아웃을 찾을수 없어 custom-footer.html에 추가한다.\n\r 아래 코드를 복하하여 custom-footer.html에 붙여넣는다.  \u0026lt;script src=\u0026#34;https://utteranc.es/client.js\u0026#34;\rrepo=\u0026#34;user id/blog-comments\u0026#34;\rissue-term=\u0026#34;title\u0026#34;\rtheme=\u0026#34;github-light\u0026#34;\rcrossorigin=\u0026#34;anonymous\u0026#34;\rasync\u0026gt;\r\u0026lt;/script\u0026gt; \r첫 로딩시 댓글 기능은 비활성화되어 있고 github 로그인 인증을 통해 해당 리파지터리에서 utterances app 사용을 승인하면 이후 댓글 기능을 사용할 수 있다. 댓글의 경우 생성한 리파지터리의 Issues 생성 기능을 통해 동작한다.\n\r댓글 삭제 해당 기능은 따로 제공하지 않는것 같다. 직접 리파지터리에서 이슈로 이동후 본인이 등록한 이슈를 삭제하자\n댓글 기능 상단의 Comment를 누르면 댓글 리파지터리의 이슈탭으로 이동한다. 이곳에서 삭제하자\n"
},
{
	"uri": "https://hnc-hskim.github.io/hugo/",
	"title": "Hugoes",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://hnc-hskim.github.io/cloud/operation/scheduling/",
	"title": "Scheduling",
	"tags": [],
	"description": "",
	"content": "노드에 파드 할당하기 특정한 노드(들) 집합에서만 동작하도록 파드를 제한할 수 있다. 이를 수행하는 방법에는 여러 가지가 있으며 권장되는 접근 방식은 모두 레이블 셀렉터를 사용하여 선택을 용이하게 한다. 보통은 스케줄러가 자동으로 합리적인 배치(예: 자원이 부족한 노드에 파드를 배치하지 않도록 노드 간에 파드를 분배)를 수행하기에 이러한 제약 조건은 필요하지 않다. 그러나, 예를 들어 SSD가 장착된 머신에 파드가 배포되도록 하거나 또는 많은 통신을 하는 두 개의 서로 다른 서비스의 파드를 동일한 가용성 영역(availability zone)에 배치하는 경우와 같이, 파드가 어느 노드에 배포될지를 제어해야 하는 경우도 있다.\n방법  노드 레이블에 매칭되는 nodeSelector 필드 어피니티 / 안티 어피니티 nodeName 필드  1. 노드 레이블 다른 쿠버네티스 오브젝트와 마찬가지로, 노드도 레이블을 가진다. 레이블을 수동으로 추가할 수 있다. 또한 쿠버네티스도 클러스터의 모든 노드에 표준화된 레이블 집합을 적용한다. 잘 알려진 레이블, 어노테이션, 테인트에서 널리 사용되는 노드 레이블의 목록을 확인한다.\n 노드 조회  $ kubectl get nodes\rNAME STATUS ROLES AGE VERSION\rip-10-83-80-162.ap-northeast-2.compute.internal Ready \u0026lt;none\u0026gt; 6d15h v1.21.12-eks-5308cf7\rip-10-83-82-103.ap-northeast-2.compute.internal Ready \u0026lt;none\u0026gt; 6d15h v1.21.12-eks-5308cf7\rip-10-83-84-128.ap-northeast-2.compute.internal Ready \u0026lt;none\u0026gt; 6d15h v1.21.12-eks-5308cf7  노드 레이블 조회  $ kubectl get nodes --show-labels\rNAME STATUS ROLES AGE VERSION LABELS\rip-10-83-80-162.ap-northeast-2.compute.internal Ready \u0026lt;none\u0026gt; 6d15h v1.21.12-eks-5308cf7 beta.kubernetes.io/arch=amd64,beta.kubernetes.io/instance-type=m5.2xlarge,beta.kubernetes.io/os=linux,eks.amazonaws.com/capacityType=ON_DEMAND,eks.amazonaws.com/nodegroup-image=ami-0918f823d29c638d9,eks.amazonaws.com/nodegroup=black-nodegroup-20220708083127543500000015,eks.amazonaws.com/sourceLaunchTemplateId=lt-01141f4c6a453c7f0,eks.amazonaws.com/sourceLaunchTemplateVersion=1,failure-domain.beta.kubernetes.io/region=ap-northeast-2,failure-domain.beta.kubernetes.io/zone=ap-northeast-2a,kubernetes.io/arch=amd64,kubernetes.io/hostname=ip-10-83-80-162.ap-northeast-2.compute.internal,kubernetes.io/os=linux,node.kubernetes.io/instance-type=m5.2xlarge,topology.ebs.csi.aws.com/zone=ap-northeast-2a,topology.kubernetes.io/region=ap-northeast-2,topology.kubernetes.io/zone=ap-northeast-2a\rip-10-83-82-103.ap-northeast-2.compute.internal Ready \u0026lt;none\u0026gt; 6d15h v1.21.12-eks-5308cf7 beta.kubernetes.io/arch=amd64,beta.kubernetes.io/instance-type=m5.2xlarge,beta.kubernetes.io/os=linux,eks.amazonaws.com/capacityType=ON_DEMAND,eks.amazonaws.com/nodegroup-image=ami-0918f823d29c638d9,eks.amazonaws.com/nodegroup=black-nodegroup-20220708083127543500000015,eks.amazonaws.com/sourceLaunchTemplateId=lt-01141f4c6a453c7f0,eks.amazonaws.com/sourceLaunchTemplateVersion=1,failure-domain.beta.kubernetes.io/region=ap-northeast-2,failure-domain.beta.kubernetes.io/zone=ap-northeast-2b,kubernetes.io/arch=amd64,kubernetes.io/hostname=ip-10-83-82-103.ap-northeast-2.compute.internal,kubernetes.io/os=linux,node.kubernetes.io/instance-type=m5.2xlarge,topology.ebs.csi.aws.com/zone=ap-northeast-2b,topology.kubernetes.io/region=ap-northeast-2,topology.kubernetes.io/zone=ap-northeast-2b\rip-10-83-84-128.ap-northeast-2.compute.internal Ready \u0026lt;none\u0026gt; 6d15h v1.21.12-eks-5308cf7 beta.kubernetes.io/arch=amd64,beta.kubernetes.io/instance-type=m5.2xlarge,beta.kubernetes.io/os=linux,eks.amazonaws.com/capacityType=ON_DEMAND,eks.amazonaws.com/nodegroup-image=ami-0918f823d29c638d9,eks.amazonaws.com/nodegroup=black-nodegroup-20220708083127543500000015,eks.amazonaws.com/sourceLaunchTemplateId=lt-01141f4c6a453c7f0,eks.amazonaws.com/sourceLaunchTemplateVersion=1,failure-domain.beta.kubernetes.io/region=ap-northeast-2,failure-domain.beta.kubernetes.io/zone=ap-northeast-2c,kubernetes.io/arch=amd64,kubernetes.io/hostname=ip-10-83-84-128.ap-northeast-2.compute.internal,kubernetes.io/os=linux,node.kubernetes.io/instance-type=m5.2xlarge,topology.ebs.csi.aws.com/zone=ap-northeast-2c,topology.kubernetes.io/region=ap-northeast-2,topology.kubernetes.io/zone=ap-northeast-2c  호스트 이름으로 조회  $ kubectl describe nodes ip-10-83-80-162.ap-northeast-2.compute.internal\rName: ip-10-83-80-162.ap-northeast-2.compute.internal\rRoles: \u0026lt;none\u0026gt;\rLabels: beta.kubernetes.io/arch=amd64\rbeta.kubernetes.io/instance-type=m5.2xlarge\rbeta.kubernetes.io/os=linux\reks.amazonaws.com/capacityType=ON_DEMAND\reks.amazonaws.com/nodegroup=black-nodegroup-20220708083127543500000015\reks.amazonaws.com/nodegroup-image=ami-0918f823d29c638d9\reks.amazonaws.com/sourceLaunchTemplateId=lt-01141f4c6a453c7f0\reks.amazonaws.com/sourceLaunchTemplateVersion=1\rfailure-domain.beta.kubernetes.io/region=ap-northeast-2\rfailure-domain.beta.kubernetes.io/zone=ap-northeast-2a\rkubernetes.io/arch=amd64\rkubernetes.io/hostname=ip-10-83-80-162.ap-northeast-2.compute.internal\rkubernetes.io/os=linux\rnode.kubernetes.io/instance-type=m5.2xlarge\rtopology.ebs.csi.aws.com/zone=ap-northeast-2a\rtopology.kubernetes.io/region=ap-northeast-2\rtopology.kubernetes.io/zone=ap-northeast-2a\rAnnotations: csi.volume.kubernetes.io/nodeid: {\u0026#34;ebs.csi.aws.com\u0026#34;:\u0026#34;i-0f255f242c1b4616e\u0026#34;,\u0026#34;efs.csi.aws.com\u0026#34;:\u0026#34;i-0f255f242c1b4616e\u0026#34;}\rnode.alpha.kubernetes.io/ttl: 0\rvolumes.kubernetes.io/controller-managed-attach-detach: true\rCreationTimestamp: Fri, 08 Jul 2022 17:32:26 +0900\rTaints: \u0026lt;none\u0026gt;\rUnschedulable: false\rLease:\rHolderIdentity: ip-10-83-80-162.ap-northeast-2.compute.internal\rAcquireTime: \u0026lt;unset\u0026gt;\rRenewTime: Fri, 15 Jul 2022 08:58:03 +0900\rConditions:\rType Status LastHeartbeatTime LastTransitionTime Reason Message\r---- ------ ----------------- ------------------ ------ -------\rMemoryPressure False Fri, 15 Jul 2022 08:55:51 +0900 Fri, 08 Jul 2022 17:32:26 +0900 KubeletHasSufficientMemory kubelet has sufficient memory available\rDiskPressure False Fri, 15 Jul 2022 08:55:51 +0900 Fri, 08 Jul 2022 17:32:26 +0900 KubeletHasNoDiskPressure kubelet has no disk pressure\rPIDPressure False Fri, 15 Jul 2022 08:55:51 +0900 Fri, 08 Jul 2022 17:32:26 +0900 KubeletHasSufficientPID kubelet has sufficient PID available\rReady True Fri, 15 Jul 2022 08:55:51 +0900 Fri, 08 Jul 2022 17:32:47 +0900 KubeletReady kubelet is posting ready status\rAddresses:\rInternalIP: 10.83.80.162\rHostname: ip-10-83-80-162.ap-northeast-2.compute.internal\rInternalDNS: ip-10-83-80-162.ap-northeast-2.compute.internal\rCapacity:\rattachable-volumes-aws-ebs: 25\rcpu: 8\rephemeral-storage: 20959212Ki\rhugepages-1Gi: 0\rhugepages-2Mi: 0\rmemory: 32408676Ki\rpods: 58\rAllocatable:\rattachable-volumes-aws-ebs: 25\rcpu: 7910m\rephemeral-storage: 18242267924\rhugepages-1Gi: 0\rhugepages-2Mi: 0\rmemory: 31391844Ki\rpods: 58\rSystem Info:\rMachine ID: ec2cf9fd6e8ff9955c3f7269a4a9d3da\rSystem UUID: ec2cf9fd-6e8f-f995-5c3f-7269a4a9d3da\rBoot ID: c48572a6-8e6d-427b-b5b4-f9f21e8e0838\rKernel Version: 5.4.196-108.356.amzn2.x86_64\rOS Image: Amazon Linux 2\rOperating System: linux\rArchitecture: amd64\rContainer Runtime Version: docker://20.10.13\rKubelet Version: v1.21.12-eks-5308cf7\rKube-Proxy Version: v1.21.12-eks-5308cf7\rProviderID: aws:///ap-northeast-2a/i-0f255f242c1b4616e\rNon-terminated Pods: (19 in total)\rNamespace Name CPU Requests CPU Limits Memory Requests Memory Limits Age\r--------- ---- ------------ ---------- --------------- ------------- ---\rcode-server code-server-84f85bfbb7-q9rs5 0 (0%) 0 (0%) 0 (0%) 0 (0%) 42h\rgatekeeper-system gatekeeper-controller-manager-77768dcc76-fmggf 100m (1%) 1 (12%) 256Mi (0%) 512Mi (1%) 19h\rkube-system alb-controller-aws-load-balancer-controller-579798fdbf-5w8zb 0 (0%) 0 (0%) 0 (0%) 0 (0%) 6d14h\rkube-system aws-cluster-autoscaler-84bd9c55fb-k28ps 0 (0%) 0 (0%) 0 (0%) 0 (0%) 6d14h\rkube-system aws-node-lsfh6 25m (0%) 0 (0%) 0 (0%) 0 (0%) 6d15h\rkube-system coredns-6dbb778559-5vn52 100m (1%) 0 (0%) 70Mi (0%) 170Mi (0%) 6d15h\rkube-system ebs-csi-node-q6df6 0 (0%) 0 (0%) 0 (0%) 0 (0%) 6d14h\rkube-system efs-csi-controller-664994d876-9wqqx 0 (0%) 0 (0%) 0 (0%) 0 (0%) 17h\rkube-system efs-csi-node-4x5tj 0 (0%) 0 (0%) 0 (0%) 0 (0%) 17h\rkube-system kube-proxy-26nsg 100m (1%) 0 (0%) 0 (0%) 0 (0%) 6d15h\rlinkerd-viz tap-766dd477f8-x2m94 200m (2%) 100m (1%) 70Mi (0%) 500Mi (1%) 16h\rlinkerd linkerd-destination-7c8564ff97-g8gf6 300m (3%) 100m (1%) 120Mi (0%) 750Mi (2%) 16h\rlinkerd linkerd-identity-67bcfd69d4-l94zv 200m (2%) 100m (1%) 30Mi (0%) 500Mi (1%) 16h\rlinkerd linkerd-proxy-injector-6f464ddc76-98wj4 200m (2%) 100m (1%) 70Mi (0%) 500Mi (1%) 16h\rlitmus subscriber-cd959f546-4g8kx 125m (1%) 225m (2%) 300Mi (0%) 500Mi (1%) 21h\rlitmus workflow-controller-856d568f68-wt6dj 125m (1%) 225m (2%) 300Mi (0%) 500Mi (1%) 21h\rlog-stack fluentd-ccwzk 300m (3%) 300m (3%) 1Gi (3%) 1Gi (3%) 46h\rlog-stack opensearch-cluster-coordinate-0 1 (12%) 1 (12%) 2Gi (6%) 2Gi (6%) 46h\rlog-stack opensearch-cluster-master-0 1 (12%) 1 (12%) 2Gi (6%) 2Gi (6%) 46h\rAllocated resources:\r(Total limits may be over 100 percent, i.e., overcommitted.)\rResource Requests Limits\r-------- -------- ------\rcpu 3775m (47%) 4150m (52%)\rmemory 6336Mi (20%) 9052Mi (29%)\rephemeral-storage 1000Mi (5%) 2Gi (11%)\rhugepages-1Gi 0 (0%) 0 (0%)\rhugepages-2Mi 0 (0%) 0 (0%)\rattachable-volumes-aws-ebs 0 0\rEvents: \u0026lt;none\u0026gt;  적용된 레이블 확인  Labels: beta.kubernetes.io/arch=amd64\rbeta.kubernetes.io/instance-type=m5.2xlarge\rbeta.kubernetes.io/os=linux\reks.amazonaws.com/capacityType=ON_DEMAND\reks.amazonaws.com/nodegroup=black-nodegroup-20220708083127543500000015\reks.amazonaws.com/nodegroup-image=ami-0918f823d29c638d9\reks.amazonaws.com/sourceLaunchTemplateId=lt-01141f4c6a453c7f0\reks.amazonaws.com/sourceLaunchTemplateVersion=1\rfailure-domain.beta.kubernetes.io/region=ap-northeast-2\rfailure-domain.beta.kubernetes.io/zone=ap-northeast-2a\rkubernetes.io/arch=amd64\rkubernetes.io/hostname=ip-10-83-80-162.ap-northeast-2.compute.internal\rkubernetes.io/os=linux\rnode.kubernetes.io/instance-type=m5.2xlarge\rtopology.ebs.csi.aws.com/zone=ap-northeast-2a\rtopology.kubernetes.io/region=ap-northeast-2\rtopology.kubernetes.io/zone=ap-northeast-2a  현재 스케줄링중인 pod 상태  Namespace Name CPU Requests CPU Limits Memory Requests Memory Limits Age\r--------- ---- ------------ ---------- --------------- ------------- ---\rcode-server code-server-84f85bfbb7-q9rs5 0 (0%) 0 (0%) 0 (0%) 0 (0%) 42h\rgatekeeper-system gatekeeper-controller-manager-77768dcc76-fmggf 100m (1%) 1 (12%) 256Mi (0%) 512Mi (1%) 19h\rkube-system alb-controller-aws-load-balancer-controller-579798fdbf-5w8zb 0 (0%) 0 (0%) 0 (0%) 0 (0%) 6d14h\rkube-system aws-cluster-autoscaler-84bd9c55fb-k28ps 0 (0%) 0 (0%) 0 (0%) 0 (0%) 6d14h\rkube-system aws-node-lsfh6 25m (0%) 0 (0%) 0 (0%) 0 (0%) 6d15h\rkube-system coredns-6dbb778559-5vn52 100m (1%) 0 (0%) 70Mi (0%) 170Mi (0%) 6d15h\rkube-system ebs-csi-node-q6df6 0 (0%) 0 (0%) 0 (0%) 0 (0%) 6d14h\rkube-system efs-csi-controller-664994d876-9wqqx 0 (0%) 0 (0%) 0 (0%) 0 (0%) 17h\rkube-system efs-csi-node-4x5tj 0 (0%) 0 (0%) 0 (0%) 0 (0%) 17h\rkube-system kube-proxy-26nsg 100m (1%) 0 (0%) 0 (0%) 0 (0%) 6d15h\rlinkerd-viz tap-766dd477f8-x2m94 200m (2%) 100m (1%) 70Mi (0%) 500Mi (1%) 16h\rlinkerd linkerd-destination-7c8564ff97-g8gf6 300m (3%) 100m (1%) 120Mi (0%) 750Mi (2%) 16h\rlinkerd linkerd-identity-67bcfd69d4-l94zv 200m (2%) 100m (1%) 30Mi (0%) 500Mi (1%) 16h\rlinkerd linkerd-proxy-injector-6f464ddc76-98wj4 200m (2%) 100m (1%) 70Mi (0%) 500Mi (1%) 16h\rlitmus subscriber-cd959f546-4g8kx 125m (1%) 225m (2%) 300Mi (0%) 500Mi (1%) 21h\rlitmus workflow-controller-856d568f68-wt6dj 125m (1%) 225m (2%) 300Mi (0%) 500Mi (1%) 21h\rlog-stack fluentd-ccwzk 300m (3%) 300m (3%) 1Gi (3%) 1Gi (3%) 46h\rlog-stack opensearch-cluster-coordinate-0 1 (12%) 1 (12%) 2Gi (6%) 2Gi (6%) 46h\rlog-stack opensearch-cluster-master-0 1 (12%) 1 (12%) 2Gi (6%) 2Gi (6%) 46h  리소스 사용 현황을 보자 cpu 점유율이 47%이다.  Allocated resources:\r(Total limits may be over 100 percent, i.e., overcommitted.)\rResource Requests Limits\r-------- -------- ------\rcpu 3775m (47%) 4150m (52%)\rmemory 6336Mi (20%) 9052Mi (29%)\rephemeral-storage 1000Mi (5%) 2Gi (11%)\rhugepages-1Gi 0 (0%) 0 (0%)\rhugepages-2Mi 0 (0%) 0 (0%)\rattachable-volumes-aws-ebs 0 0 label을 이용한 특정 Node에 Pod 배포 테스트를 위해 nginx app을 1개 배포해 보자.\n 네임스페이스를 생성한다.(scheduling-test)  $ kubectl create namespace scheduling-test\rnamespace/scheduling-test created  label 추가  kubectl label nodes [node_name] [key]=[value]\r$ kubectl label nodes ip-10-83-80-162.ap-northeast-2.compute.internal key=mytest-node\rnode/ip-10-83-80-162.ap-northeast-2.compute.internal labeled\r# 레이블 삭제\rkubectl label nodes mytest-node key-  레이블 확인(key : mytest-node)  $ kubectl describe nodes ip-10-83-80-162.ap-northeast-2.compute.internal\rName: ip-10-83-80-162.ap-northeast-2.compute.internal\rRoles: \u0026lt;none\u0026gt;\rLabels: beta.kubernetes.io/arch=amd64\rbeta.kubernetes.io/instance-type=m5.2xlarge\rbeta.kubernetes.io/os=linux\reks.amazonaws.com/capacityType=ON_DEMAND\reks.amazonaws.com/nodegroup=black-nodegroup-20220708083127543500000015\reks.amazonaws.com/nodegroup-image=ami-0918f823d29c638d9\reks.amazonaws.com/sourceLaunchTemplateId=lt-01141f4c6a453c7f0\reks.amazonaws.com/sourceLaunchTemplateVersion=1\rfailure-domain.beta.kubernetes.io/region=ap-northeast-2\rfailure-domain.beta.kubernetes.io/zone=ap-northeast-2a\rkey=mytest-node\rkubernetes.io/arch=amd64\rkubernetes.io/hostname=ip-10-83-80-162.ap-northeast-2.compute.internal\rkubernetes.io/os=linux\rnode.kubernetes.io/instance-type=m5.2xlarge\rtopology.ebs.csi.aws.com/zone=ap-northeast-2a\rtopology.kubernetes.io/region=ap-northeast-2\rtopology.kubernetes.io/zone=ap-northeast-2a  scheduling.yaml  apiVersion: apps/v1\rkind: Deployment\rmetadata:\rname: my-nginx\rnamespace: scheduling-test\rlabels:\rapp: my-nginx\rspec:\rreplicas: 3\rselector:\rmatchLabels:\rapp: my-nginx\rtemplate:\rmetadata:\rlabels:\rapp: my-nginx\rspec:\rcontainers:\r- name: my-nginx\rimage: nginx:1.14.2\rports:\r- containerPort: 80\rresources:\rrequests: cpu: \u0026#34;500m\u0026#34;\rlimits: cpu: \u0026#34;1000m\u0026#34;\rnodeSelector:\rkey: mytest-node\r---\rapiVersion: v1\rkind: Service\rmetadata:\rname: my-nginx\rnamespace: scheduling-test\rlabels:\rrun: my-nginx\rspec:\rports:\r- port: 80\rtargetPort: 80\rprotocol: TCP\rselector:\rapp: my-nginx\r---\rapiVersion: extensions/v1beta1\rkind: Ingress\rmetadata:\rname: scheduling-ingress\rnamespace: scheduling-test\rannotations:\rkubernetes.io/ingress.class: nginx\rspec:\rrules:\r- host: nginxtest.black.cloud.hancom.com\rhttp:\rpaths:\r- backend:\rserviceName: my-nginx\rservicePort: 80  배포  $ kubectl apply -f .\\nodeselectortest.yaml\rdeployment.apps/my-nginx created\rservice/my-nginx created ingress.extensions/scheduling-ingress created  pod 상태 조회  $ kubectl get pods -n scheduling-test\rNAME READY STATUS RESTARTS AGE\rmy-nginx-5b5f4bdd49-qwk7x 1/1 Running 0 9s  node 상태 조회  ......\rNon-terminated Pods: (20 in total)\rNamespace Name CPU Requests CPU Limits Memory Requests Memory Limits Age\r--------- ---- ------------ ---------- --------------- ------------- ---\rcode-server code-server-84f85bfbb7-q9rs5 0 (0%) 0 (0%) 0 (0%) 0 (0%) 43h\rgatekeeper-system gatekeeper-controller-manager-77768dcc76-fmggf 100m (1%) 1 (12%) 256Mi (0%) 512Mi (1%) 20h\rkube-system alb-controller-aws-load-balancer-controller-579798fdbf-5w8zb 0 (0%) 0 (0%) 0 (0%) 0 (0%) 6d15h\rkube-system aws-cluster-autoscaler-84bd9c55fb-k28ps 0 (0%) 0 (0%) 0 (0%) 0 (0%) 6d15h\rkube-system aws-node-lsfh6 25m (0%) 0 (0%) 0 (0%) 0 (0%) 6d15h\rkube-system coredns-6dbb778559-5vn52 100m (1%) 0 (0%) 70Mi (0%) 170Mi (0%) 6d16h\rkube-system ebs-csi-node-q6df6 0 (0%) 0 (0%) 0 (0%) 0 (0%) 6d15h\rkube-system efs-csi-controller-664994d876-9wqqx 0 (0%) 0 (0%) 0 (0%) 0 (0%) 17h\rkube-system efs-csi-node-4x5tj 0 (0%) 0 (0%) 0 (0%) 0 (0%) 17h\rkube-system kube-proxy-26nsg 100m (1%) 0 (0%) 0 (0%) 0 (0%) 6d15h\rlinkerd-viz tap-766dd477f8-x2m94 200m (2%) 100m (1%) 70Mi (0%) 500Mi (1%) 16h\rlinkerd linkerd-destination-7c8564ff97-g8gf6 300m (3%) 100m (1%) 120Mi (0%) 750Mi (2%) 16h\rlinkerd linkerd-identity-67bcfd69d4-l94zv 200m (2%) 100m (1%) 30Mi (0%) 500Mi (1%) 16h\rlinkerd linkerd-proxy-injector-6f464ddc76-98wj4 200m (2%) 100m (1%) 70Mi (0%) 500Mi (1%) 16h\rlitmus subscriber-cd959f546-4g8kx 125m (1%) 225m (2%) 300Mi (0%) 500Mi (1%) 22h\rlitmus workflow-controller-856d568f68-wt6dj 125m (1%) 225m (2%) 300Mi (0%) 500Mi (1%) 22h\rlog-stack fluentd-ccwzk 300m (3%) 300m (3%) 1Gi (3%) 1Gi (3%) 47h\rlog-stack opensearch-cluster-coordinate-0 1 (12%) 1 (12%) 2Gi (6%) 2Gi (6%) 47h\rlog-stack opensearch-cluster-master-0 1 (12%) 1 (12%) 2Gi (6%) 2Gi (6%) 47h\rscheduling-test my-nginx-5b5f4bdd49-qwk7x 500m (6%) 1 (12%) 0 (0%) 0 (0%) 90s\rAllocated resources:\r(Total limits may be over 100 percent, i.e., overcommitted.)\rResource Requests Limits\r-------- -------- ------\rcpu 4275m (54%) 5150m (65%)\rmemory 6336Mi (20%) 9052Mi (29%)\rephemeral-storage 1000Mi (5%) 2Gi (11%)\rhugepages-1Gi 0 (0%) 0 (0%)\rhugepages-2Mi 0 (0%) 0 (0%)\rattachable-volumes-aws-ebs 0 0 Deployment를 수정해 리소스 제한 요청을 늘려보자  기존 리소스 삭제  $ kubectl delete -f nodeselectortest.yaml deployment.apps \u0026#34;my-nginx\u0026#34; deleted\rservice \u0026#34;my-nginx\u0026#34; deleted ingress.extensions \u0026#34;scheduling-ingress\u0026#34; deleted resources:\rrequests: cpu: \u0026#34;5000m\u0026#34;\rlimits: cpu: \u0026#34;6000m\u0026#34;  현재 상태 확인  $ kubectl describe nodes ip-10-83-80-162.ap-northeast-2.compute.internal\r.....\rNon-terminated Pods: (19 in total)\rNamespace Name CPU Requests CPU Limits Memory Requests Memory Limits Age\r--------- ---- ------------ ---------- --------------- ------------- ---\rcode-server code-server-84f85bfbb7-q9rs5 0 (0%) 0 (0%) 0 (0%) 0 (0%) 43h\rgatekeeper-system gatekeeper-controller-manager-77768dcc76-fmggf 100m (1%) 1 (12%) 256Mi (0%) 512Mi (1%) 20h\rkube-system alb-controller-aws-load-balancer-controller-579798fdbf-5w8zb 0 (0%) 0 (0%) 0 (0%) 0 (0%) 6d15h\rkube-system aws-cluster-autoscaler-84bd9c55fb-k28ps 0 (0%) 0 (0%) 0 (0%) 0 (0%) 6d15h\rkube-system aws-node-lsfh6 25m (0%) 0 (0%) 0 (0%) 0 (0%) 6d16h\rkube-system coredns-6dbb778559-5vn52 100m (1%) 0 (0%) 70Mi (0%) 170Mi (0%) 6d16h\rkube-system ebs-csi-node-q6df6 0 (0%) 0 (0%) 0 (0%) 0 (0%) 6d15h\rkube-system efs-csi-controller-664994d876-9wqqx 0 (0%) 0 (0%) 0 (0%) 0 (0%) 18h\rkube-system efs-csi-node-4x5tj 0 (0%) 0 (0%) 0 (0%) 0 (0%) 18h\rkube-system kube-proxy-26nsg 100m (1%) 0 (0%) 0 (0%) 0 (0%) 6d16h\rlinkerd-viz tap-766dd477f8-x2m94 200m (2%) 100m (1%) 70Mi (0%) 500Mi (1%) 16h\rlinkerd linkerd-destination-7c8564ff97-g8gf6 300m (3%) 100m (1%) 120Mi (0%) 750Mi (2%) 16h\rlinkerd linkerd-identity-67bcfd69d4-l94zv 200m (2%) 100m (1%) 30Mi (0%) 500Mi (1%) 16h\rlinkerd linkerd-proxy-injector-6f464ddc76-98wj4 200m (2%) 100m (1%) 70Mi (0%) 500Mi (1%) 16h\rlitmus subscriber-cd959f546-4g8kx 125m (1%) 225m (2%) 300Mi (0%) 500Mi (1%) 22h\rlitmus workflow-controller-856d568f68-wt6dj 125m (1%) 225m (2%) 300Mi (0%) 500Mi (1%) 22h\rlog-stack fluentd-ccwzk 300m (3%) 300m (3%) 1Gi (3%) 1Gi (3%) 47h\rlog-stack opensearch-cluster-coordinate-0 1 (12%) 1 (12%) 2Gi (6%) 2Gi (6%) 47h\rlog-stack opensearch-cluster-master-0 1 (12%) 1 (12%) 2Gi (6%) 2Gi (6%) 47h\rAllocated resources:\r(Total limits may be over 100 percent, i.e., overcommitted.)\rResource Requests Limits\r-------- -------- ------\rcpu 3775m (47%) 4150m (52%)\rmemory 6336Mi (20%) 9052Mi (29%)\rephemeral-storage 1000Mi (5%) 2Gi (11%)\rhugepages-1Gi 0 (0%) 0 (0%)\rhugepages-2Mi 0 (0%) 0 (0%)\rattachable-volumes-aws-ebs 0 0\rEvents: \u0026lt;none\u0026gt;  배포후 pod 상태 확인  $ kubectl apply -f nodeselectortest.yaml\rdeployment.apps/my-nginx created\rservice/my-nginx created ingress.extensions/scheduling-ingress created\r$ kubectl get pods -n scheduling-test\rNAME READY STATUS RESTARTS AGE\rmy-nginx-7cbcf9fb8d-lqcpg 0/1 Pending 0 13s  로그 조회  $ kubectl describe pods/my-nginx-7cbcf9fb8d-lqcpg -n scheduling-test\rEvents:\rType Reason Age From Message\r---- ------ ---- ---- -------\rWarning FailedScheduling 5m28s (x2 over 5m29s) default-scheduler 0/3 nodes are available: 1 Insufficient cpu, 2 node(s) didn\u0026#39;t match Pod\u0026#39;s node affinity/selector.\rNormal TriggeredScaleUp 5m26s cluster-autoscaler pod triggered scale-up: [{eks-black-nodegroup-20220708083127543500000015-58c0ee77-b6ac-cd2a-5d95-c6d8c8c059b3 3-\u0026gt;4 (max: 6)}]\rWarning FailedScheduling 4m15s (x3 over 4m43s) default-scheduler 0/4 nodes are available: 1 Insufficient cpu, 1 node(s) had taint {node.kubernetes.io/not-ready: }, that the pod didn\u0026#39;t tolerate, 2 node(s) didn\u0026#39;t match Pod\u0026#39;s node affinity/selector.\rWarning FailedScheduling 3m55s (x2 over 4m5s) default-scheduler 0/4 nodes are available: 1 Insufficient cpu, 3 node(s) didn\u0026#39;t match Pod\u0026#39;s node affinity/selector.\rWarning FailedScheduling 2m51s (x3 over 3m19s) default-scheduler 0/5 nodes are available: 1 Insufficient cpu, 1 node(s) had taint {node.kubernetes.io/not-ready: }, that the pod didn\u0026#39;t tolerate, 3 node(s) didn\u0026#39;t match Pod\u0026#39;s node affinity/selector.\rWarning FailedScheduling 2m31s (x2 over 2m41s) default-scheduler 0/5 nodes are available: 1 Insufficient cpu, 4 node(s) didn\u0026#39;t match Pod\u0026#39;s node affinity/selector.\rWarning FailedScheduling 93s (x3 over 2m1s) default-scheduler 0/6 nodes are available: 1 Insufficient cpu, 1 node(s) had taint {node.kubernetes.io/not-ready: }, that the pod didn\u0026#39;t tolerate, 4 node(s) didn\u0026#39;t match Pod\u0026#39;s node affinity/selector.\rWarning FailedScheduling 72s (x2 over 82s) default-scheduler 0/6 nodes are available: 1 Insufficient cpu, 5 node(s) didn\u0026#39;t match Pod\u0026#39;s node affinity/selector.\rNormal NotTriggerScaleUp 24s (x10 over 2m35s) cluster-autoscaler pod didn\u0026#39;t trigger scale-up: 1 max node group size reached 확인 결과 Running중인 pod의 드레인이나 리스케줄링 같은 특이상황은 관찰되지 않았으며, 리소스 부족으로 오토스케일링이 발생하여 max 값까지 노드들이 증가하지만 레이블이 존재하지 않으므로 pod 배포에 실패한다.\npriorityClassName 적용후 동작 확인  priorityClass 적용  nodeSelector:\rkey: mytest-node\rpriorityClassName: system-cluster-critical  배포 성공 및 기존 pod 드레인 확인  Non-terminated Pods: (16 in total)\rNamespace Name CPU Requests CPU Limits Memory Requests Memory Limits Age\r--------- ---- ------------ ---------- --------------- ------------- ---\rcode-server code-server-84f85bfbb7-q9rs5 0 (0%) 0 (0%) 0 (0%) 0 (0%) 43h\rgatekeeper-system gatekeeper-controller-manager-77768dcc76-fmggf 100m (1%) 1 (12%) 256Mi (0%) 512Mi (1%) 20h\rkube-system alb-controller-aws-load-balancer-controller-579798fdbf-5w8zb 0 (0%) 0 (0%) 0 (0%) 0 (0%) 6d15h\rkube-system aws-cluster-autoscaler-84bd9c55fb-k28ps 0 (0%) 0 (0%) 0 (0%) 0 (0%) 6d15h\rkube-system aws-node-lsfh6 25m (0%) 0 (0%) 0 (0%) 0 (0%) 6d16h\rkube-system coredns-6dbb778559-5vn52 100m (1%) 0 (0%) 70Mi (0%) 170Mi (0%) 6d16h\rkube-system ebs-csi-node-q6df6 0 (0%) 0 (0%) 0 (0%) 0 (0%) 6d15h\rkube-system efs-csi-controller-664994d876-9wqqx 0 (0%) 0 (0%) 0 (0%) 0 (0%) 18h\rkube-system efs-csi-node-4x5tj 0 (0%) 0 (0%) 0 (0%) 0 (0%) 18h\rkube-system kube-proxy-26nsg 100m (1%) 0 (0%) 0 (0%) 0 (0%) 6d16h\rlitmus subscriber-cd959f546-4g8kx 125m (1%) 225m (2%) 300Mi (0%) 500Mi (1%) 22h\rlitmus workflow-controller-856d568f68-wt6dj 125m (1%) 225m (2%) 300Mi (0%) 500Mi (1%) 22h\rlog-stack fluentd-ccwzk 300m (3%) 300m (3%) 1Gi (3%) 1Gi (3%) 47h\rlog-stack opensearch-cluster-coordinate-0 1 (12%) 1 (12%) 2Gi (6%) 2Gi (6%) 47h\rlog-stack opensearch-cluster-master-0 1 (12%) 1 (12%) 2Gi (6%) 2Gi (6%) 47h\rscheduling-test my-nginx-7c9849cffb-nr6gn 5 (63%) 6 (75%) 0 (0%) 0 (0%) 99s\rAllocated resources:\r(Total limits may be over 100 percent, i.e., overcommitted.)\rResource Requests Limits\r-------- -------- ------\rcpu 7875m (99%) 9750m (123%)\rmemory 6046Mi (19%) 6802Mi (22%)\rephemeral-storage 1000Mi (5%) 2Gi (11%)\rhugepages-1Gi 0 (0%) 0 (0%)\rhugepages-2Mi 0 (0%) 0 (0%)\rattachable-volumes-aws-ebs 0 0\rEvents: \u0026lt;none\u0026gt; 결론 우선순위가 낮은 pod들이 이동되는것을 확인함\n"
},
{
	"uri": "https://hnc-hskim.github.io/hugo/style/",
	"title": "Style",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://hnc-hskim.github.io/",
	"title": "",
	"tags": [],
	"description": "",
	"content": "Contents  kubernetes  CLI   workshop  MSA    A notice disclaimer\n\rAn information disclaimer\n\rA tip disclaimer\n\rA warning disclaimer\n\r"
},
{
	"uri": "https://hnc-hskim.github.io/kubernetes/",
	"title": "Kubernetes",
	"tags": [],
	"description": "",
	"content": "CLI 사용법 "
},
{
	"uri": "https://hnc-hskim.github.io/kubernetes/aws-cli/",
	"title": "Aws Cli",
	"tags": [],
	"description": "",
	"content": "aws 계정 정보 조회 aws sts get-caller-identity --profile \u0026#34;name\u0026#34; kubeconfig 등록 aws eks --profile \u0026#34;profile name\u0026#34; update-kubeconfig --name \u0026#34;cluster name\u0026#34; --region ap-northeast-2 "
},
{
	"uri": "https://hnc-hskim.github.io/kubernetes/cli/",
	"title": "Cli",
	"tags": [],
	"description": "",
	"content": "조회(All) $ kubectl get all -n code-server\rNAME READY STATUS RESTARTS AGE\rpod/code-server-5fc775748c-nbmsr 0/1 Init:CrashLoopBackOff 5 4m31s\rNAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE\rservice/code-server ClusterIP 10.79.240.159 \u0026lt;none\u0026gt; 8080/TCP 13m\rNAME READY UP-TO-DATE AVAILABLE AGE\rdeployment.apps/code-server 0/1 1 0 13m\rNAME DESIRED CURRENT READY AGE\rreplicaset.apps/code-server-5879f94445 0 0 0 7m13s\rreplicaset.apps/code-server-5fc775748c 1 1 0 4m31s\rreplicaset.apps/code-server-67d7c4f6cd 0 0 0 13m kubectl 버전 조회 # orca\r$ kubectl version --short | grep -i server\rFlag --short has been deprecated, and will be removed in the future. The --short output will become the default.\rWARNING: version difference between client (1.24) and server (1.21) exceeds the supported minor version skew of +/-1\rServer Version: v1.21.12 # black\r$ kubectl version --short | grep -i server\rFlag --short has been deprecated, and will be removed in the future. The --short output will become the default.\rWARNING: version difference between client (1.24) and server (1.21) exceeds the supported minor version skew of +/-1\rServer Version: v1.21.13-eks-84b4fe6 리소스 쿼터 조회 kubectl get resourcequota -n \u0026#34;namespace\u0026#34; 컨텍스트 조회 kubectl config get-contexts 컨텍스트 사용 kubectl config use-context \u0026#34;context name\u0026#34; 클러스터명 조회 kubectl config view --minify -o jsonpath=\u0026#39;{.clusters[].name}\u0026#39; 노드에 레이블 추가 # 레이블 추가\rkubectl label nodes \u0026lt;your-node-name\u0026gt; disktype=ssd\r# 레이블 확인\rkubectl get nodes --show-labels Evicted pod 제거 kubectl delete pods --field-selector=status.phase=Failed -A Node 재시작 kubectl describe node/hcidc-sv-paz-orca-worker-08\rkubectl uncordon hcidc-sv-paz-orca-worker-08 node describe kubectl describe nodes \u0026#34;nodes-name\u0026#34; Disk-Pressure 해결  테인트 수동 제거 시도(제거 안됨)  kubectl taint nodes hcidc-sv-paz-orca-worker-08 node.kubernetes.io/disk-pressure-  워커 노드에 직접 접속해 해결  ssh uname@IP_or_hostname (login to the worker node )\rdf -h (to check the disk usage)\rrm -rf folder_name (delete the unwanted folder,you are forcefully deleting the file, so make sure you really want to delete it). yaml edit kubectl edit service/ocr-service -n mlops\rkubectl edit Ingress/mlops-ingress -n mlops\rkubectl edit endpoints/ocr-service -n mlops\rkubectl edit service/ingress-nginx-controller -n ingress-nginx https://kubernetes.io/ko/docs/concepts/services-networking/service-traffic-policy/\nversion 확인 kubectl version --short\rFlag --short has been deprecated, and will be removed in the future. The --short output will become the default.\rClient Version: v1.24.1\rKustomize Version: v4.5.4\rServer Version: v1.21.14-eks-6d3986b\rWARNING: version difference between client (1.24) and server (1.21) exceeds the supported minor version skew of +/-1 aws eks describe-cluster --name black --region ap-northeast-2\r{\r\u0026#34;cluster\u0026#34;: {\r\u0026#34;name\u0026#34;: \u0026#34;black\u0026#34;,\r\u0026#34;arn\u0026#34;: \u0026#34;arn:aws:eks:ap-northeast-2:258092954359:cluster/black\u0026#34;,\r\u0026#34;createdAt\u0026#34;: \u0026#34;2022-08-25T15:46:42.441000+09:00\u0026#34;,\r\u0026#34;version\u0026#34;: \u0026#34;1.21\u0026#34;,\r\u0026#34;endpoint\u0026#34;: \u0026#34;https://C711862DD49EF2914B647C7921AC60AC.gr7.ap-northeast-2.eks.amazonaws.com\u0026#34;,\r\u0026#34;roleArn\u0026#34;: \u0026#34;arn:aws:iam::258092954359:role/black-cluster-20220825064630881900000007\u0026#34;,\r\u0026#34;resourcesVpcConfig\u0026#34;: {\r\u0026#34;subnetIds\u0026#34;: [\r\u0026#34;subnet-05d5ecf440385c7e8\u0026#34;,\r\u0026#34;subnet-04eae96a716680c0d\u0026#34;,\r\u0026#34;subnet-00f80af8e448a8e94\u0026#34;,\r\u0026#34;subnet-0b7d86c89170e2b16\u0026#34;,\r\u0026#34;subnet-0dda057aa012c87cd\u0026#34;,\r\u0026#34;subnet-0d13e4d3b276e382e\u0026#34;,\r\u0026#34;subnet-09f35944ad3b7f1b2\u0026#34;,\r\u0026#34;subnet-01977f8d12d297273\u0026#34;\r],\r\u0026#34;securityGroupIds\u0026#34;: [\r\u0026#34;sg-083204ef197bed7d8\u0026#34;\r],\r\u0026#34;clusterSecurityGroupId\u0026#34;: \u0026#34;sg-01ee12c4df0f3adb4\u0026#34;,\r\u0026#34;vpcId\u0026#34;: \u0026#34;vpc-0223d4132cf21dfe6\u0026#34;,\r\u0026#34;endpointPublicAccess\u0026#34;: true,\r\u0026#34;endpointPrivateAccess\u0026#34;: true,\r\u0026#34;publicAccessCidrs\u0026#34;: [\r\u0026#34;0.0.0.0/0\u0026#34;\r]\r},\r\u0026#34;kubernetesNetworkConfig\u0026#34;: {\r\u0026#34;serviceIpv4Cidr\u0026#34;: \u0026#34;10.79.0.0/16\u0026#34;,\r\u0026#34;ipFamily\u0026#34;: \u0026#34;ipv4\u0026#34;\r},\r\u0026#34;logging\u0026#34;: {\r\u0026#34;clusterLogging\u0026#34;: [\r{\r\u0026#34;types\u0026#34;: [\r\u0026#34;api\u0026#34;,\r\u0026#34;audit\u0026#34;,\r\u0026#34;authenticator\u0026#34;\r],\r\u0026#34;enabled\u0026#34;: true\r},\r{\r\u0026#34;types\u0026#34;: [\r\u0026#34;controllerManager\u0026#34;,\r\u0026#34;scheduler\u0026#34;\r],\r\u0026#34;enabled\u0026#34;: false\r}\r]\r},\r\u0026#34;identity\u0026#34;: {\r\u0026#34;oidc\u0026#34;: {\r\u0026#34;issuer\u0026#34;: \u0026#34;https://oidc.eks.ap-northeast-2.amazonaws.com/id/C711862DD49EF2914B647C7921AC60AC\u0026#34;\r}\r},\r\u0026#34;status\u0026#34;: \u0026#34;ACTIVE\u0026#34;,\r\u0026#34;certificateAuthority\u0026#34;: {\r\u0026#34;data\u0026#34;: \u0026#34;LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSUM1ekNDQWMrZ0F3SUJBZ0lCQURBTkJna3Foa2lHOXcwQkFRc0ZBREFWTVJNd0VRWURWUVFERXdwcmRXSmwKY201bGRHVnpNQjRYRFRJeU1EZ3lOVEEyTlRJeE4xb1hEVE15TURneU1qQTJOVEl4TjFvd0ZURVRNQkVHQTFVRQpBeE1LYTNWaVpYSnVaWFJsY3pDQ0FTSXdEUVlKS29aSWh2Y05BUUVCQlFBRGdnRVBBRENDQVFvQ2dnRUJBS3NFCktyK0k0eVhlN0Y4eDU5bkhHK3lwZjhheDhJWVdJenBpVHZVRGVCNmNmYWRJM0pTMDhEeWtPMEF5cEswVjBrMFIKOGRqQjdIMEVHOTJnOFlIbG5XdDZ0OVk3VE05NzhHVk9PR3Y2ZVBSUFFRRGNvL2dSam9MTTR3RExhaVJYUndOSQpnbEM5ZWd6eWtxRWYxYWwyeG5UY0RRUWZvcG5EanZ2Snd1THpPbmRucEU1M3FwS1lvNTh3NktZWjFjVHlHMHFaCnVWRHE0M3dObC9WcW5TL3BzUFQxRkQ5S1laNEhnNXJnMU9MRGhTQy8rSVdUb2xFUjB2WWZzQk5PVy80dVNFU2kKMmUwbjJJaVpyVzJVT1dlRTlScXV3bnRNY2h0U1pYWWNDKzNzV3hUcklvZE1pek9lRWg1aGZaa1g2ZFZFSVZ4egphT2NBRGNjZmxiUUQvQ2xGQ3RFQ0F3RUFBYU5DTUVBd0RnWURWUjBQQVFIL0JBUURBZ0trTUE4R0ExVWRFd0VCCi93UUZNQU1CQWY4d0hRWURWUjBPQkJZRUZIRmJISTFoSHRGZjVpN1VKZ2srZS9Da3FXQVBNQTBHQ1NxR1NJYjMKRFFFQkN3VUFBNElCQVFCbmdSVHBTT2t1WFFoVEJwTjBUTVQ2alA4NWpkdGZJRmZ6NWFXMDZpVlppM3ZnZ1lOMApmZ05yczZrV3FsYXdVVWRtYm5EdmZEU1kwWXh6dzVMKytZaDlMcURpNjdvbWhLdmJOaEFoQTN4dDgvL2tUdVZQClVuVGVsWWE0YTdHL0VBWGkyZlYyL3B2c2NCWlV5WWt5eUtxVjlGMlQxRnhBWkhVT3p1QVBTc2xjOVhjQy9wdkQKalVXTWN3ci8yN0lxUzhzcTRRN243c2NJa2JZMURNREpxWDNUVFVRWlhucTgvY1pCUFVzRHV2RzRJaDgzMmVMYQpFS0N1RTJmVXhXN3NOdU5rMEswcG5iT2duVjJBVVdnOEFFbTFvdlhUb2hGeUY3UmtMd1oxZ2lRbjdIVzVmNU1TClh2TUVSS05kU0p2R0szVGoxMWY5TmtET0IrekpvMnVvU3FNZQotLS0tLUVORCBDRVJUSUZJQ0FURS0tLS0tCg==\u0026#34;\r},\r\u0026#34;platformVersion\u0026#34;: \u0026#34;eks.11\u0026#34;,\r\u0026#34;tags\u0026#34;: {\r\u0026#34;Terraform\u0026#34;: \u0026#34;true\u0026#34;,\r\u0026#34;Environment\u0026#34;: \u0026#34;stg\u0026#34;\r},\r\u0026#34;encryptionConfig\u0026#34;: [\r{\r\u0026#34;resources\u0026#34;: [\r\u0026#34;secrets\u0026#34;\r],\r\u0026#34;provider\u0026#34;: {\r\u0026#34;keyArn\u0026#34;: \u0026#34;arn:aws:kms:ap-northeast-2:258092954359:key/ac5e33f5-88ad-44fa-a52c-69e93fe97352\u0026#34;\r}\r}\r]\r}\r} "
},
{
	"uri": "https://hnc-hskim.github.io/workshop/msa/",
	"title": "Msa",
	"tags": [],
	"description": "",
	"content": "[netflex microservice] https://netflixtechblog.com/tagged/microservices\n마이크로서비스는 소프트웨어가 잘 정의된 API를 통해 통신하는 소규모의 독립적인 서비스로 구성되어 있는 경우의 소프트웨어 개발을 위한 아키텍처 및 조직적 접근 방식입니다.\n이러한 서비스는 독립적인 소규모 팀에서 보유합니다. 마이크로서비스 아키텍처는 애플리케이션의 확장을 용이하게 하고 개발 속도를 앞당겨 혁신을 실현하고 새로운 기능의 출시 시간을 단축할 수 있게 해 줍니다.\n\rMain featrues 1. MSA 소개 2. Software Architecture 3. 10 Common Software Architectural Patterns Goals  소프트웨어 아키텍처가 필요한 이유 모놀리식 아키텍처 계층화된 아키텍처 마이크로 서비스 아키텍처  마이크로서비스 아키텍처의 경우, 애플리케이션이 독립적인 구성 요소로 구축되어 각 애플리케이션 프로세스가 서비스로 실행됩니다. 이러한 서비스는 경량 API를 사용하여 잘 정의된 인터페이스를 통해 통신합니다. 서비스는 비즈니스 기능을 위해 구축되며 서비스마다 한 가지 기능을 수행합니다. 서비스가 독립적으로 실행되기 때문에 애플리케이션의 특정 기능에 대한 수요를 충족하도록 각각의 서비스를 업데이트, 배포 및 확장할 수 있습니다.\n[출처] https://aws.amazon.com/ko/microservices/\n[참고] http://guruble.com/%EB%A7%88%EC%9D%B4%ED%81%AC%EB%A1%9C%EC%84%9C%EB%B9%84%EC%8A%A4microservice-%EC%95%84%ED%82%A4%ED%85%8D%EC%B2%98-%EA%B7%B8%EA%B2%83%EC%9D%B4-%EB%AD%A3%EC%9D%B4-%EC%A4%91%ED%97%8C%EB%94%94/\nReferences  http://www.msaschool.io/operation/implementation/implementation-five/  "
},
{
	"uri": "https://hnc-hskim.github.io/cloud/isms-p/job/",
	"title": "",
	"tags": [],
	"description": "",
	"content": "참고 참고\n참고 - EBS-backed Linux AMI 생성\n처리 방법\n EC2 생성   AMI ID : ami-0d4bbf30d9907be82  EIP 할당 및 접속   취약점 조치  AMI 이미지 생성  [1번] ■ 기준: /etc/pam.d/system-auth(common-auth) 파일에 아래와 같은 설정이 있으면 양호 ■ : (auth required /lib/security/pam_tally.so deny=5 unlock_time=120 no_magic_root) ■ : (account required /lib/security/pam_tally.so no_magic_root reset) ■ 현황\n☞ /etc/pam.d/system-auth 파일 설정(auth, account) User changes will be destroyed the next time authconfig is run. auth required pam_env.so auth sufficient pam_unix.so try_first_pass nullok auth required pam_deny.so account required pam_unix.so password requisite pam_pwquality.so try_first_pass local_users_only retry=3 authtok_type= password sufficient pam_unix.so try_first_pass use_authtok nullok sha512 shadow\n[2번] ■ 기준1: /etc/pam.d/su 파일 설정이 아래와 같을 경우 양호 ■ 기준2: 아래 설정이 없거나, 주석 처리가 되어 있을 경우 양호 ■ 기준3: su 명령 파일의 권한이 4750 이고 특정 그룹만 사용 할 수 있도록 제한 되어있으면 양호 ■ : (auth required /lib/security/pam_wheel.so debug group=wheel) 또는 ■ : (auth required /lib/security/$ISA/pam_wheel.so use_uid) ■ 현황\n① /etc/pam.d/su 파일 설정 #auth\trequired\tpam_wheel.so use_uid\n② su 파일권한 -rwsr-xr-x 1 root root 32032 Apr 14 2022 /bin/su\n③ su 명령그룹  su명령 그룹(명령파일): root:x:0:  Result=M/T\n[3번] \u0026ldquo;■ 기준: 패스워드 최소 길이가 8자 이상으로 설정되어 있으면 양호 ■ : (PASS_MIN_LEN 8 이상이면 양호) ■ 현황\n◈Debian 현재 패스워드 정책 확인 Last password change\t: Dec 22, 2009 Password expires\t: never Password inactive\t: never Account expires\t: never Minimum number of days between password change\t: -1 Maximum number of days between password change\t: -1 Number of days of warning before password expires\t: -1\n/etc/pam.d/common-password 파일 내용 (Debian 계열) /etc/pam.d/common-password 파일이 없습니다.\nResult=Disabled:Null\n[4번] ■ 기준: 패스워드 최대 사용기간이 180일 이하로 설정되어 있으면 양호 ■ : (PASS_MAX_DAYS 180 이하이면 양호) ■ 현황\n◈Debian 현재 패스워드 정책 확인 Last password change\t: Dec 22, 2009 Password expires\t: never Password inactive\t: never Account expires\t: never Minimum number of days between password change\t: -1 Maximum number of days between password change\t: -1 Number of days of warning before password expires\t: -1 PASS_MAX_DAYS\t99999\nResult=99999\n[5번] ■ 기준: 패스워드 최소 사용기간이 1일로 설정되어 있으면 양호 ■ : (PASS_MIN_DAYS 1 이상이면 양호) ■ 현황\nPASS_MIN_DAYS\t0\nResult=0\n[6번] ■ 기준: /etc/profile 에서 TMOUT=600 또는 /etc/csh.login 에서 autologout=10으로 설정되어 있으면 양호 ■ : (1) sh, ksh, bash 쉘의 경우 /etc/profile 파일 설정을 적용받음 ■ : (2) csh, tcsh 쉘의 경우 /etc/csh.cshrc 또는 /etc/csh.login 파일 설정을 적용받음 ■ 현황\n☞ 현재 로그인 계정 TMOUT TMOUT 이 설정되어 있지 않습니다.\n☞ TMOUT 설정 확인\n① /etc/profile 파일 TMOUT 이 설정되어 있지 않습니다.\n② /etc/csh.login 파일 autologout 이 설정되어 있지 않습니다.\n③ /etc/csh.cshrc 파일 autologout 이 설정되어 있지 않습니다.\nResult=M/T\n[7번] ■ 기준: 불필요한 SUID/SGID 설정이 존재하지 않을 경우 양호 ■ 현황\n주요정보통신기반시설 가이드 부록 기준 불필요한 SUID,SGID,Sticky Bit 설정 파일 -rwsr-xr-x 1 root root 41712 Aug 1 2018 /usr/bin/newgrp -rwsr-xr-x 1 root root 36176 Sep 24 2020 /usr/sbin/unix_chkpwd\nSUID,SGID,Sticky bit 설정 파일 (상위 10개) -r-xr-sr-x 1 root tty 15264 Aug 1 2018 /usr/bin/wall -rwsr-xr-x 1 root root 64160 Aug 1 2018 /usr/bin/chage -rwsr-xr-x 1 root root 78128 Aug 1 2018 /usr/bin/gpasswd -rwsr-xr-x 1 root root 41712 Aug 1 2018 /usr/bin/newgrp -rwsr-xr-x 1 root root 35952 Apr 14 2022 /usr/bin/mount -rwsr-xr-x 1 root root 57504 Jan 16 2020 /usr/bin/crontab -rwsr-xr-x 1 root root 32032 Apr 14 2022 /usr/bin/su -rwsr-xr-x 1 root root 27776 Apr 14 2022 /usr/bin/umount -rwxr-sr-x 1 root tty 19472 Apr 14 2022 /usr/bin/write \u0026mdash;s\u0026ndash;x\u0026ndash;x 1 root root 147240 Feb 8 2021 /usr/bin/sudo\n등 총 22개 파일 존재 (전체 목록은 스크립트 결과 파일 확인)\nResult=22\n[8번] ■ 기준: 불필요한 권한이 부여된 world writable 파일이 존재하지 않을 경우 양호 ■ 현황\nWorld Writable 파일 (상위 10개) srw-rw-rw- : root : root : /var/lib/gssproxy/default.sock drwxrwxrwt : root : root : /var/lib/docker/containers/e5a45c29cbcfd1e1a9c25273dfb3bdf07b8334111ca089b55ea465591598ffab/mounts/shm drwxrwxrwt : root : root : /var/lib/docker/containers/e65712b6cac554f72af0b66941282844cd011c3bc20629733690a31f5c07a7b1/mounts/shm drwxrwxrwt : root : root : /var/lib/docker/containers/c7ad27866d2fc10a6873c8ce16ad6056a9d3961f1e23e4de60bae643d35290bf/mounts/shm drwxrwxrwt : root : root : /var/lib/docker/containers/965d77ce6713b0c5db800526f77eef3b7b71b09ad517246afb2a82f0a4e952ef/mounts/shm drwxrwxrwt : root : root : /var/lib/docker/containers/153bc367267a2d9e935c8a63bbafc6516829931c87f014aea7cbfced54b02622/mounts/shm drwxrwxrwt : root : root : /var/lib/docker/containers/c0a34c528c36943d292e89d5760daf5007ab3422722a27ef538d8e9b27593b1b/mounts/shm drwxrwxrwt : root : root : /var/lib/docker/containers/c3bfc18f314926c952784cc721f6ca040a3706f22984433ff9734ebe070f6064/mounts/shm drwxrwxrwt : root : root : /var/lib/docker/containers/20afeeba0c4c3fe3c6057d0fb2570dd523738fb88caba330cb831af5eae048dd/mounts/shm drwxrwxrwt : root : root : /var/lib/docker/containers/9e00d742c23436adb7408b8d8a5d62ff102dfbb0257dbc0619e0fd9e913f536d/mounts/shm\n등 총 1349개 파일 존재 (전체 목록은 스크립트 결과 파일 확인)\nResult=1349\n[9번] ■ 기준 : dev 에 존재하지 않은 Device 파일을 점검하고, 존재하지 않은 Device을 제거 했을 경우 양호 ■ : (아래 나열된 결과는 major, minor Number를 갖지 않는 파일임) ■ : (.devlink_db_lock/.devfsadm_daemon.lock/.devfsadm_synch_door/.devlink_db는 Default로 존재 예외) ■ 현황\n-rwxr-xr-x 1 root root 0 Aug 25 07:04 /dev/termination-log\nResult=M/T\n[10번] ■ 기준1: /etc/hosts.deny 파일에 All Deny(ALL:ALL) 설정이 등록되어 있고, ■ 기준2: /etc/hosts.allow 파일에 접근 허용 IP가 등록되어 있으면 양호 ■ 현황\n① /etc/hosts.allow 파일 설정 설정 내용이 없습니다.\n② /etc/hosts.deny 파일 설정 설정 내용이 없습니다.\nResult=M/T\n[11번] ■ 기준: 로그기록에 대해 정기적 검토, 분석, 리포트 작성 및 보고가 이루어지고 있는 경우 양호 ■ 현황 ㅇ Opensearch 를 통한 주기적으로 로그 수집을 하고 있으나 수집된 로그에 대하여 정기적인 검토 및 분석이 이루어 지지 않고 있으므로 취약 처리\u0026rdquo;\n[12번] ■ 기준: 패스워드 복잡도 설정이 되어있으면 양호 ■ 현황\n◈Debian 현재 패스워드 정책 확인 Last password change\t: Dec 22, 2009 Password expires\t: never Password inactive\t: never Account expires\t: never Minimum number of days between password change\t: -1 Maximum number of days between password change\t: -1 Number of days of warning before password expires\t: -1\n  ◈libpam-cracklib 모듈사용시_/etc/pam.d/common-password 파일 설정 확인 password [success=2 default=ignore] pam_unix.so obscure sha512 내용 확인 /etc/pam.d/common-password cat: /etc/pam.d/common-password: No such file or directory\n Result=M/T\n\u0026quot;\n"
},
{
	"uri": "https://hnc-hskim.github.io/categories/",
	"title": "Categories",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://hnc-hskim.github.io/tags/",
	"title": "Tags",
	"tags": [],
	"description": "",
	"content": ""
}]